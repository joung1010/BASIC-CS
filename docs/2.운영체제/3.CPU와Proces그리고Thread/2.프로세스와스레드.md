## 프로세스와 스레드

### 기본 개념과 관계

**프로세스는 관리의 단위**이고 이 주체는 **OS**이다. 결국 프로세스도 처리해야 할 연산들이고, 이 연산들은 **연속적인 흐름**을 가진다. 프로세스 레벨에서는 이 흐름이 **1개가 존재**하고 이 프로세스는 **반드시 한 개의 스레드**를 가진다.

이때 이 흐름이 **n개일 때** 이 각 흐름들은 **동시에 각자 독립적으로** 동작한다. 그리고 이 흐름들에서 **각 실행들을 스레드**라고 하고 이 실행들이 여러 개가 있으면 **멀티스레딩**이라고 한다.

### 프로세스와 스레드의 구조적 관계

```
프로세스 (Process) - OS의 관리 단위
├─ 흐름1 ────────────────────────────────────────────>
│  ├─ 스레드 실행 ──┐
│  ├─ 스레드 실행 ──┤  
│  ├─ 스레드 실행 ──┤  독립적 실행 흐름
│  └─ 스레드 실행 ──┘
│
├─ 흐름2 ────────────────────────────────────────────>
│  ├─ 스레드 실행 ──┐
│  ├─ 스레드 실행 ──┤  병렬 처리
│  └─ 스레드 실행 ──┘
│
└─ 흐름n ────────────────────────────────────────────>
   ├─ 스레드 실행 ──┐
   └─ 스레드 실행 ──┘
```

### 시스템 자원 할당과 가상 메모리

```
┌─────────────────────────────────────────────────────────┐
│                     User Mode                          │
│  ┌─────────────────┐    ┌─────────────────────────────┐ │
│  │    프로세스     │    │      가상 메모리            │ │
│  │    연산코드     │◄──►│   (Virtual Memory)          │ │
│  │                 │    │                             │ │
│  └─────────────────┘    └─────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
═══════════════════════════════════════════════════════════
┌─────────────────────────────────────────────────────────┐
│                   Kernel Mode                          │
│                      OS                                │
│              (자원 관리 및 할당)                        │
└─────────────────────────────────────────────────────────┘
═══════════════════════════════════════════════════════════
┌─────────────────────────────────────────────────────────┐
│                    Hardware                            │
│  ┌─────────────────┐    ┌─────────────────────────────┐ │
│  │      CPU        │    │          RAM               │ │
│  │ 코어0, 코어1,   │    │     (물리 메모리)           │ │
│  │ 코어2, 코어3    │    │                             │ │
│  └─────────────────┘    └─────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

### 자원 할당 과정과 가상 메모리의 역할

**프로세스 실행을 위한 자원 할당 과정**:

1. **CPU 할당**: 운영체제가 "CPU 0번을 주고 이걸 사용해서 연산 처리해!"라고 지시
2. **메모리 할당**: CPU는 연산에 필요한 **연습장(RAM)**이 필요하다고 요청
3. **가상 메모리 제공**: OS가 연산에 필요한 메모리를 **Virtual Memory 형태로 관리**하여 제공

**가상 메모리의 추상화 개념**:

```
가상 메모리 (연속된 주소 공간)
┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐
│  0  │  1  │  2  │  3  │  4  │  5  │  6  │  7  │ ← 논리적 주소
└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘
   ↓     ↓     ↓     ↓     ↓     ↓     ↓     ↓
┌─────┬─────┐     ┌─────┬─────┐     ┌─────┬─────┐
│RAM  │RAM  │     │HDD  │HDD  │     │RAM  │SSD  │ ← 실제 물리적 위치
└─────┴─────┘     └─────┴─────┘     └─────┴─────┘
```

이 **Virtual Memory는 1차 메모리인 RAM과 2차 메모리인 HDD/SSD를 합쳐서 추상화**시킨 것으로, 이 연속된 가상 메모리를 실제 따라가 보면 **RAM인 경우도 있고 HDD인 경우도** 있을 수 있다.

### 가구와 세대원 비유 - TLS와 Heap의 이해

**프로세스를 가구, 스레드를 세대원으로 비유**하면 더 쉽게 이해할 수 있다:

```
🏠 프로세스 (가구) - OS에게 할당받은 집
┌─────────────────────────────────────────────────────────┐
│  👨 스레드1     👩 스레드2     👦 스레드3     👧 스레드4   │
│   (세대원1)     (세대원2)     (세대원3)     (세대원4)    │
│                                                         │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐    │
│  │ 개인방1 │  │ 개인방2 │  │ 개인방3 │  │ 개인방4 │    │
│  │   TLS   │  │   TLS   │  │   TLS   │  │   TLS   │    │
│  │ (Thread │  │ (Thread │  │ (Thread │  │ (Thread │    │
│  │ Local   │  │ Local   │  │ Local   │  │ Local   │    │
│  │Storage) │  │Storage) │  │Storage) │  │Storage) │    │
│  └─────────┘  └─────────┘  └─────────┘  └─────────┘    │
│                                                         │
│  ┌─────────────────────────────────────────────────┐   │
│  │              거실 (공용 공간)                    │   │
│  │                 Heap Memory                     │   │
│  │   - 모든 세대원이 공유하는 공간                  │   │
│  │   - 공용 가구, 물건들 보관                      │   │
│  │   - 함께 사용하는 자원들                        │   │
│  └─────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

### 프로세스와 스레드의 메모리 공유

**핵심 원칙들**:

- **Process(작업)는 최소 1개의 Thread가 존재**한다. 그래서 우리가 **프로세스 내에서의 연산은 스레드 단위로 진행**되게 된다.
- **OS는 이 Virtual Memory(제한된 공간)를 Process에게 할당**한다.
- **Process에 속한 모든 스레드는 프로세스의 가상 메모리로 공간이 제약**된다.
- **각 스레드는 고유한 TLS(Thread Local Storage)를 가지고 있다**. 따라서 **스레드들은 프로세스에게 운영체제로부터 할당받은 공간에서 모여 살고 있다**.

### 메모리 영역별 상세 분석

**프로세스 가상 메모리 구조**:

```
높은 주소 (0xFFFFFFFF)
┌─────────────────────────────────────┐
│            Kernel Space              │ ← OS 전용 영역
├─────────────────────────────────────┤
│     Stack (각 스레드별 독립)         │ ← 개인방 (TLS 포함)
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐   │
│  │TLS1 │ │TLS2 │ │TLS3 │ │TLS4 │   │ ← Thread Local Storage
│  │Stack│ │Stack│ │Stack│ │Stack│   │
│  │  1  │ │  2  │ │  3  │ │  4  │   │
│  └─────┘ └─────┘ └─────┘ └─────┘   │
├─────────────────────────────────────┤
│               ↓↑                    │ ← 동적 확장 영역
│         (Stack ↔ Heap 경계)         │
├─────────────────────────────────────┤
│              Heap                   │ ← 거실 (모든 스레드 공유)
│        (동적 메모리 할당)            │   공용 가구, 데이터
│      모든 스레드가 공유 영역         │
├─────────────────────────────────────┤
│              BSS                    │ ← 모든 스레드가 공유
│      (초기화되지 않은 전역변수)       │
├─────────────────────────────────────┤
│             Data                    │ ← 모든 스레드가 공유
│       (초기화된 전역변수)            │
├─────────────────────────────────────┤
│             Text                    │ ← 모든 스레드가 공유
│          (실행 코드)                 │
└─────────────────────────────────────┘
낮은 주소 (0x00000000)
```

### Thread Local Storage (TLS) 상세 설명

**TLS의 개념과 특징**:

```c
*// 각 스레드마다 독립적인 TLS 변수*
__thread int thread_id;           *// 각 스레드별로 다른 값*
__thread char buffer[1024];       *// 각 스레드별로 독립적인 버퍼*
__thread FILE* log_file;          *// 각 스레드별로 다른 파일 핸들*

void thread_function(void* arg) {
    thread_id = getCurrentThreadId();  *// 각 스레드마다 다른 ID 저장*
    sprintf(buffer, "Thread %d log", thread_id);  *// 독립적인 버퍼 사용*
    
    *// TLS는 각 스레드의 "개인방"에 저장됨// 다른 스레드가 접근할 수 없음*
}
```

**TLS 활용 예시**:

```java
// Java에서의 ThreadLocal 사용*
public class ThreadLocalExample {
    // 각 스레드별로 독립적인 값을 가지는 변수*
    private static ThreadLocal<Integer> threadLocalValue = new ThreadLocal<Integer>() {
        @Override
        protected Integer initialValue() {
            return 0;  // 각 스레드별 초기값*
        }
    };
    
    public static void main(String[] args) {
        // 3개의 스레드가 각각 독립적인 TLS 공간을 가짐*
        for (int i = 0; i < 3; i++) {
            final int threadNum = i;
            new Thread(() -> {
                // 각 스레드가 자신만의 값을 설정 (개인방에 물건 보관)*
                threadLocalValue.set(threadNum * 100);
                
                System.out.println("Thread " + threadNum + 
                    " TLS value: " + threadLocalValue.get());
                // Thread 0 TLS value: 0// Thread 1 TLS value: 100  // Thread 2 TLS value: 200*
            }).start();
        }
    }
}
```

### 스레드별 자원 공유와 독립성

**개인방 (TLS) - 각 스레드가 독립적으로 소유**:

- **TLS 변수**: 스레드별로 고유한 값 저장
- **레지스터**: CPU 레지스터 상태값
- **프로그램 카운터**: 현재 실행 중인 명령어 위치
- **스택**: 함수 호출 스택과 지역 변수
- **스레드 ID**: 각 스레드의 고유 식별자

**거실 (Heap) - 모든 스레드가 공유하는 공간**:

- **힙 메모리**: `malloc()`, `new` 등으로 할당된 동적 메모리
- **전역 변수**: 모든 스레드가 접근 가능한 변수들
- **파일 디스크립터**: 열린 파일들
- **시그널 핸들러**: 신호 처리 함수
- **코드 영역**: 실행할 프로그램 코드

### 실제 TLS와 Heap 사용 예시

**C++에서의 TLS와 공유 메모리 사용**:

```cpp
#include <thread>
#include <iostream>

*// 거실 (Heap) - 모든 스레드가 공유*
int shared_counter = 0;           *// 공용 카운터*
std::mutex counter_mutex;         *// 공용 자원 보호용 뮤텍스// 개인방 (TLS) - 각 스레드별로 독립*
thread_local int private_counter = 0;  *// 각 스레드만의 카운터*

void worker_thread(int thread_id) {
    *// 개인방에서 작업 (TLS 사용)*
    private_counter = thread_id * 10;
    
    for (int i = 0; i < 5; i++) {
        *// 개인방에서 혼자 작업*
        private_counter++;
        
        *// 거실에서 공용 작업 (동기화 필요)*
        {
            std::lock_guard<std::mutex> lock(counter_mutex);
            shared_counter++;  *// 공용 자원 접근*
        }
        
        std::cout << "Thread " << thread_id 
                  << " - Private: " << private_counter 
                  << ", Shared: " << shared_counter << std::endl;
    }
}

int main() {
    std::thread t1(worker_thread, 1);  *// 세대원 1*
    std::thread t2(worker_thread, 2);  *// 세대원 2*
    
    t1.join();
    t2.join();
    
    return 0;
}
```

### 스케줄링과 CPU 할당

**OS의 스레드 스케줄링**:

CPU 코어 할당:
시간 t1: 코어0 → 스레드1(TLS1), 코어1 → 스레드2(TLS2)
시간 t2: 코어0 → 스레드2(TLS2), 코어1 → 스레드3(TLS3)  
시간 t3: 코어0 → 스레드3(TLS3), 코어1 → 스레드1(TLS1)

각 스레드는:
- 개인방(TLS): 독립적으로 관리
- 거실(Heap): 공유하면서 동기화 필요

### 동기화의 필요성

**거실(Heap) 사용 시 주의사항**:

c

```c
*// 문제 상황: 거실에서 동시에 물건을 옮기려 할 때// 스레드1과 스레드2가 동시에 shared_data를 수정*
int shared_data = 100;  *// 거실의 공용 물건// 스레드1: shared_data = shared_data + 10;// 스레드2: shared_data = shared_data * 2;// 예상 결과: 220 또는 210// 실제 결과: 예측 불가 (Race Condition)// 해결책: 뮤텍스로 거실 사용 순서 정하기*
pthread_mutex_t room_lock;
pthread_mutex_lock(&room_lock);    *// 거실 문 잠그기*
shared_data = shared_data + 10;    *// 혼자서 안전하게 작업*
pthread_mutex_unlock(&room_lock);  *// 거실 문 열기*
```

이러한 **프로세스와 스레드의 관계**는 **가구와 세대원의 개념**으로 이해하면, **각 스레드가 독립적인 TLS(개인방)을 가지면서도 공통의 Heap(거실)을 공유**하여 효율적인 **병렬 처리와 자원 공유**를 가능하게 한다는 것을 알 수 있다.


### 컴퓨터 자원의 구성

컴퓨터에서 자원이라고 할 때는 보통 크게 **3개의 자원**을 말한다:

- **CPU**: 연산 처리 장치
- **RAM**: 주기억장치
- **HDD/SSD**: 보조기억장치 (추가적인 자원)

그리고 **주기억장치 RAM과 보조기억장치 HDD/SSD를 합쳐서 Virtual Memory 형태로 관리**된다.

### 자원 할당 방식의 차이

그래서 이 자원을 **운영체제마다 차이가 있지만** 보통 **프로세스에게 할당**한다. **Windows 같은 경우는 스레드에게 할당**한다.

**Linux/Unix 계열**:

```
OS → Process → Thread
자원 할당 단위: Process
스케줄링 단위: Thread
```

**Windows 계열**:

```
OS → Thread (직접 할당)
자원 할당 단위: Thread
스케줄링 단위: Thread
```

### PCB와 TCB - 프로세스와 스레드 관리

**OS 입장에서 프로세스들을 관리**해야 되는데 이때 **관리에 필요한 정보를 모아둔 것을 PCB(Process Control Block)**라고 한다.

그래서 **프로세스에 속한 스레드들은 프로세스에게 할당받은 공간에 접근**할 수 있다. 반대로 **스레드들을 관리하기 위한 정보들은 TCB(Thread Control Block)에 저장하고 관리**한다.

### 시분할 시스템의 필요성

근데 생각해보면 이 **CPU의 코어가 8개 있다고 가정했을 때** 우리가 PC에서 현재 실행 중인 프로세스를 확인해보면 **그 많은 프로세스들의 각 연산들을 고작 CPU 코어 8개에 부탁해서 처리**하고 있으면 **병목 현상이 발생하지 않을까** 하는 생각을 할 수 있다.

**현실적 상황**:

```
실행 중인 프로세스: 200~500개
사용 가능한 CPU 코어: 4~16개
→ 물리적으로 동시 처리 불가능!
```

그러한 문제를 해결해주는 것이 바로 **OS**인데 OS에서 이러한 **병목 현상이 생기지 않게끔 프로세스들을 관리**하고 **CPU 역시 본인이 가지고 있는 자원을 시분할 사용을 통해 이를 해결**한다. (**특정 프로세스가 잠깐 사용하고 다른 프로세스가 해당 자원을 사용한다. 이러한 방식을 시분할**)

**시분할 처리 예시**:

```
Time Slice: 10ms

시간 0-10ms:   코어0→프로세스A, 코어1→프로세스B
시간 10-20ms:  코어0→프로세스C, 코어1→프로세스D  
시간 20-30ms:  코어0→프로세스A, 코어1→프로세스E
...

→ 사용자 입장에서는 모든 프로세스가 동시에 실행되는 것처럼 보임
```

### PCB(Process Control Block)의 구성 요소

그러면 과연 이 **PCB는 어떤 정보가 있어서 프로세스를 관리할 수 있는 것일까?**

**핵심 PCB 정보들**:

- **PID(프로세스 ID)**: 양의 정수 값으로 프로세스 고유 식별자
- **메모리 관련 정보**: 연산에 필요한 메모리 주소값 등을 가지고 있음
- **레지스터 정보**: CPU 레지스터 상태 백업
- **프로그램 카운터**: 현재 실행 중인 명령어 주소
- **프로세스 상태**: 생성, 준비, 실행, 대기, 완료
- **우선순위**: 스케줄링 우선순위
- **부모/자식 프로세스 정보**: 프로세스 계층 구조
- **열린 파일 목록**: 사용 중인 파일 디스크립터들

### Virtual Memory의 영역 구분

그러면 이 **Virtual Memory는 여러 영역으로 나뉘어져** 있다:

```
높은 주소 (0xFFFFFFFF)
┌─────────────────────────────────────┐
│              Stack                  │ ← 지역변수, 함수 매개변수
│         (지역 변수)                  │   함수 호출 스택
├─────────────────────────────────────┤
│               ↓↑                    │ ← 동적 확장 영역
├─────────────────────────────────────┤
│              Heap                   │ ← 동적 메모리 할당
│        (malloc, new 등)             │   런타임 시 크기 결정
├─────────────────────────────────────┤
│           Static/BSS                │ ← 정적 변수 영역
│  ┌─────────────────────────────┐   │
│  │    Read/Write 영역          │   │ ← 초기화된 전역변수
│  │    (전역변수)               │   │   프로그램 종료까지 유지
│  └─────────────────────────────┘   │
│  ┌─────────────────────────────┐   │
│  │    Read Only 영역           │   │ ← 문자열 리터럴
│  │    (문자열 상수)            │   │   수정 불가능한 데이터
│  └─────────────────────────────┘   │
├─────────────────────────────────────┤
│          Code/Text                  │ ← 실행 가능한 명령어
│        (기계어 명령)                 │   CPU가 실행할 코드
└─────────────────────────────────────┘
낮은 주소 (0x00000000)
```

### 프로그램에서 프로세스로의 전환

**설치된 프로그램을 RAM에 올려서 인스턴스화한다 → 설치 파일을 실행한다.**

**프로세스 생성 과정**:

```
1. 프로그램 실행 요청 (더블클릭, 명령어 입력)
   ↓
2. OS가 실행 파일(.exe, .out)을 분석
   ↓  
3. Virtual Memory 공간 할당
   ↓
4. 프로그램 코드를 메모리에 로드
   ↓
5. PCB 생성 및 초기화
   ↓
6. 프로세스 상태를 "생성"으로 설정
```

그래서 **실행시키면 OS는 이 프로그램을 메모리에 올리고 PCB를 생성하고 연산을 진행**한다. 이러한 상태의 프로그램을 **프로세스**라고 한다. 즉 **프로그램을 실행(인스턴스화)시켜서 CPU가 연산하는 상태를 프로세스**라고 한다.

### 프로세스 상태 전이도

그리고 이 **프로세스는 상태가 존재**하는데:

**5가지 프로세스 상태**:

1. **생성(New)**: PCB 생성, 메모리 할당 준비
2. **준비(Ready)**: 실행 준비 완료, CPU 할당 대기
3. **실행(Running)**: CPU에서 실제 명령어 실행
4. **대기(Blocked/Waiting)**: I/O 작업 등으로 일시 정지
5. **완료(Terminated)**: 실행 종료, 자원 해제

**상태 전이도**:

```
                      디스패치(Dispatch)
생성 상태 → 준비 상태  ────────────→  실행 상태 ────→ 완료 상태
         +PCB 생성   ←────────────          
                     타임아웃(인터럽트)
                     
                      ↓ 입출력 요청
                      ↓ (I/O Request)
                   대기 상태
                      ↑
                입출력 완료
               (I/O Complete)
```

### 비동기와 블로킹/논블로킹의 관계

그래서 이제는 **비동기에 대해서 조금 더 설명**을 진행하자면 **비동기는 요청자의 상태에 따라 블로킹/논블로킹이 정해진다**:

- **요청자가 비동기를 요청하고도 실행 상태이면 논블로킹**
- **요청자가 비동기를 요청하고 대기 상태로 전환한다면 블로킹**

**비동기 처리 방식 비교**:

```java
// 논블로킹 비동기*
CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {
    return slowNetworkCall();  // 백그라운드에서 실행*
});
// 메인 스레드는 계속 다른 작업 수행 (실행 상태 유지)*
doOtherWork();  
String result = future.get();  // 필요할 때 결과 획득// 블로킹 비동기*  
CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {
    return slowNetworkCall();
});
String result = future.get();  // 즉시 대기 (대기 상태로 전환)*
```

### Dispatch의 의미와 동작 원리

**Dispatch의 사전적 의미와 IT의 의미가 다르다**:

- **사전적 의미**:
    - **dispatcher**: 운행원, 관리원
    - **dispatch**: 보내다
- **IT적 관점**:
    - **dispatcher**: OS가 담당
    - **dispatch**: 보내기 전에 **보낼 대상을 선점**한다는 의미
    - **먼저 대상을 선점해야 그 대상을 보낼 수 있기 때문**
    - 즉 **dispatch라는 의미에는 보낼 데이터의 선점까지 포함**되어 있다

### 큐 기반 프로세스 스케줄링

**운영체제가 프로세스를 관리할 때 사용하는 자료구조는 Queue를 사용**한다. 그래서 **만약 프로세스가 200개이면 이 200개의 프로세스를 줄을 세워서 dispatch** 한다.

**스케줄링 큐의 동작**:

```
Ready Queue (준비 상태 프로세스들):
┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐
│ P1  │ P2  │ P3  │ P4  │ P5  │ P6  │ P7  │ P8  │
└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘
  ↑                                           ↑
 Front                                      Rear
 (다음 실행)                             (새로 추가)

CPU 코어 8개라면 → 한 번에 8개씩 꺼내서 처리
```

**만약 해당 큐가 준비 상태의 프로세스만 보관하고 있는 큐라면** 큐를 **순차적으로 디스패치해서 실행 상태로 전환**한다. 그래서 **CPU 코어 8개라면 한 번에 8개씩 꺼내서 처리**하게 되는 것이다.

**실제 스케줄링 과정**:

```
Time t1:
Ready Queue: [P1, P2, P3, P4, P5, P6, P7, P8, P9, P10, ...]
             ↓  ↓  ↓  ↓  ↓  ↓  ↓  ↓
CPU Cores:  [P1][P2][P3][P4][P5][P6][P7][P8]

Time t2 (10ms 후, 타임 슬라이스 만료):
Ready Queue: [P9, P10, P11, P12, P1, P2, P3, P4, ...]
             ↓   ↓   ↓   ↓   ↓  ↓  ↓  ↓
CPU Cores:  [P9][P10][P11][P12][P1][P2][P3][P4]
```

이러한 **프로세스 관리 시스템**을 통해 **수백 개의 프로세스가 제한된 CPU 자원을 효율적으로 공유**하여 **멀티태스킹 환경**을 구현할 수 있다.


## 프로세스 상태 sleep과 suspend

### 보류 상태를 포함한 프로세스 상태도

```
디스패치(Dispatch)
생성 상태 → 준비 상태  ────────────→  실행 상태 ────→ 완료 상태    
         +PCB 생성   ←────────────          
                     타임아웃(인터럽트)
                     
      |    ↑          ↓ 입출력 요청
      |    |  재시작   ↓ (I/O Request)                         활성 상태
      |    |      대기 상태                                    (Active)
보류   |    |  재시작 ↑  ↓ 보류                                 
      ↓    |         입출력 완료                               보류 상태
보류 준비 상태  ←   보류 대기 상태                            (Suspended)
            입출력 완료
            (인터럽트)
```

### sleep과 suspend의 본질적 차이

**suspend는 실행 흐름의 의도가 아닌 외부 요인에 의한 상태 변화**이지만 **sleep은 자발적인 상태 변화**이다.

**의도성에 따른 구분**:

- **sleep()**: "나 좀 쉴게" - **프로세스/스레드 스스로 결정**
- **suspend()**: "너 좀 치워봐" - **외부(OS, 사용자, 시스템)에서 강제**

그래서 **실행 준비 Ready Queue에서 sleep()이나 suspend() 보류가 발생하면 해당 큐에서 이탈**하게 된다.

### sleep() 메서드의 실제 동작과 지연 시간

우리가 **sleep() 메서드를 호출할 때 인자 값으로 ms를 넘겨주는데** 이때 만약 **10ms라는 인자 값을 주면 이 스레드는 10ms + 알파만큼의 시간이 소요**되는데 그 이유는 **해당 대기열에서 이탈한 다음 다시 재진입하기 때문**이다.

**sleep() 큐 이탈 및 재진입 과정**:

```
sleep() 호출 전 Ready Queue:
┌─────┬─────┬─────┬─────┬─────┐
│  1  │  2  │  3  │  4  │  5  │
└─────┴─────┴─────┴─────┴─────┘
  ↑ (1번이 sleep() 호출)

10ms 후 Ready Queue (1번 재진입):
┌─────┬─────┬─────┬─────┐
│  3  │  4  │  5  │  1  │ ← 맨 뒤로 재진입
└─────┴─────┴─────┴─────┘
```

**10ms 후에 다시 대기열 큐에 재진입한 후 앞의 연산이 전부 종료되어야 다시 연산을 실행**한다.

그래서 **큐에서 이탈한 다음에 다시 재진입할 때 알파만큼의 시간이 추가되는데 이 시간은 예측할 수가 없다**.

**실제 sleep() 지연 시간 분석**:

```c
#include <time.h>
#include <unistd.h>

// sleep(10ms) 호출 시 실제 소요 시간
clock_t start = clock();
usleep(10000);  // 10ms sleep
clock_t end = clock();

// 결과: 10ms + 스케줄링 지연 (보통 1~50ms 추가)
// 실제 소요 시간: 11~60ms (시스템 부하에 따라 가변)
```

### 컨텍스트(Context)와 컨텍스트 스위칭

그래서 **하나의 프로세스가 흐름에 따라 연산을 하고 있는데 sleep, suspend를 만나서 일시정지**가 된다.

```
프로세스 실행 흐름:
|
| 연산 진행
|
|─────── 일시 정지 (sleep/suspend)
|
| 연산 재개 (동일한 지점부터)
|
↓
```

이렇게 **일시정지가 된 다음에 다시 CPU를 사용하게 될 때 정지되었던 부분부터 흐름을 이어가야** 한다.

- 이때 등장하는 용어가 문맥(Context)이다.

### 멀티프로세스 환경에서의 컨텍스트 스위칭

**만약 CPU 코어 1개일 때**:

```
Process A          Process B          Process C
|                  |                    |
| 실행 중           | 대기               | 대기
|─── 일시정지       | 실행 시작           | 대기
| 대기              |                    |─── 일시정지
|                  |─── 일시정지         | 대기
| 실행 재개         | 대기               | 실행 시작
↓                  ↓                    ↓

시분할로 번갈아가며 실행 (각각 10ms씩 할당)
```

위의 프로세스 중 **하나의 흐름만 연산**할 것이다. 그러면 만약에 **A를 연산하고 있으면 다른 B, C는 어느 지점에서 연산을 일시정지시켜야** 한다. **A의 문맥에서 B의 문맥으로 이동하는 것을 컨텍스트 스위치**라고 한다.

### PCB에 저장되는 컨텍스트 정보

이렇게 **작업 중인 프로세스에서 다른 프로세스로 컨텍스트 스위칭할 때 PCB에 현재 상태를 저장**한다.

그러면 **어떤 상태를 저장할까? 바로 문맥을 이어가기 위한 상태, 일시정지한 지점의 정보를 저장**한다.

**실행한다는 것은 컴퓨터에게는 연산한다는 의미**이고 이 **연산의 주체는 CPU**이다. 그러면 이 **CPU가 연산을 하면 끊임없이 이 상태가 변화하게 되는데 이 상태에 대한 정보를 CPU의 Register에 저장**한다.

### PCB(Process Control Block)의 상세 구성

**PCB의 핵심 구성 요소들**:

```c
struct PCB {
    // 1. 프로세스 식별 정보
    int process_id;           // PID (Process ID)
    int parent_process_id;    // PPID (Parent Process ID)
    int user_id;             // UID (User ID)
    int group_id;            // GID (Group ID)
    
    // 2. 프로세스 상태 정보
    enum process_state {
        NEW,                 // 생성
        READY,              // 준비
        RUNNING,            // 실행
        BLOCKED,            // 대기
        SUSPENDED_READY,    // 보류 준비
        SUSPENDED_BLOCKED,  // 보류 대기
        TERMINATED          // 완료
    } state;
    
    // 3. CPU 레지스터 정보 (컨텍스트)
    struct cpu_context {
        uint64_t rax, rbx, rcx, rdx;    // 범용 레지스터
        uint64_t rsi, rdi, rbp, rsp;    // 인덱스, 포인터 레지스터
        uint64_t r8, r9, r10, r11;      // 확장 레지스터
        uint64_t r12, r13, r14, r15;
        uint64_t rip;                   // 프로그램 카운터
        uint64_t rflags;                // 상태 플래그
    } cpu_context;
    
    // 4. 메모리 관리 정보
    struct memory_info {
        void* code_base;        // 코드 영역 시작 주소
        void* data_base;        // 데이터 영역 시작 주소
        void* heap_base;        // 힙 영역 시작 주소
        void* stack_base;       // 스택 영역 시작 주소
        size_t total_size;      // 전체 메모리 크기
        struct page_table* pt;  // 페이지 테이블 포인터
    } memory;
    
    // 5. 스케줄링 정보
    int priority;               // 우선순위
    int time_slice;            // 타임 슬라이스
    clock_t cpu_time_used;     // 사용한 CPU 시간
    clock_t creation_time;     // 생성 시간
    
    // 6. I/O 및 파일 정보
    struct file_descriptor_table {
        struct file* files[MAX_FILES];  // 열린 파일들
        int count;                      // 열린 파일 개수
    } fd_table;
    
    // 7. 프로세스 관계 정보
    struct PCB* parent;         // 부모 프로세스
    struct PCB* children;       // 자식 프로세스들
    struct PCB* siblings;       // 형제 프로세스들
    
    // 8. 신호 처리 정보
    struct signal_info {
        uint64_t pending_signals;       // 대기 중인 신호
        struct sigaction handlers[64];  // 신호 핸들러들
    } signals;
    
    // 9. 동기화 정보
    struct sync_info {
        struct semaphore* waiting_on;   // 대기 중인 세마포어
        struct mutex* locked_mutexes;   // 획득한 뮤텍스들
    } sync;
};
```

### 컨텍스트 스위칭의 상세 과정

**컨텍스트 스위칭 단계별 과정**:

```c
// 1단계: 현재 프로세스 상태 저장
void save_context(struct PCB* current_pcb) {
    // CPU 레지스터 값을 PCB에 저장
    current_pcb->cpu_context.rax = get_register(RAX);
    current_pcb->cpu_context.rbx = get_register(RBX);
    current_pcb->cpu_context.rip = get_register(RIP);  // 현재 실행 위치
    // ... 모든 레지스터 저장
    
    // 메모리 맵 정보 저장
    current_pcb->memory.heap_base = get_heap_pointer();
    current_pcb->memory.stack_base = get_stack_pointer();
}

// 2단계: 다음 프로세스 상태 복원
void restore_context(struct PCB* next_pcb) {
    // PCB에서 CPU 레지스터 값 복원
    set_register(RAX, next_pcb->cpu_context.rax);
    set_register(RBX, next_pcb->cpu_context.rbx);
    set_register(RIP, next_pcb->cpu_context.rip);  // 실행 위치 복원
    // ... 모든 레지스터 복원
    
    // 메모리 맵 전환
    switch_page_table(next_pcb->memory.pt);
}

// 3단계: 완전한 컨텍스트 스위칭
void context_switch(struct PCB* current, struct PCB* next) {
    save_context(current);      // 현재 프로세스 상태 저장
    current->state = READY;     // 상태를 준비로 변경
    next->state = RUNNING;      // 다음 프로세스를 실행으로 변경
    restore_context(next);      // 다음 프로세스 상태 복원
    // 이 시점에서 완전히 다른 프로세스가 실행됨
}
```

### suspend가 발생하는 구체적 상황들

**suspend가 발생하는 경우들**:

1. **메모리 부족 상황**:

```c
// RAM이 부족할 때 비활성 프로세스를 스와핑
if (available_memory < MINIMUM_THRESHOLD) {
    suspend_least_recently_used_process();  // LRU 프로세스 suspend
    swap_to_disk(suspended_process);        // 디스크로 스왑
}
```

1. **시스템 자원 부족**:

```c
// CPU 사용률이 너무 높을 때
if (cpu_usage > 95%) {
    suspend_low_priority_processes();  // 낮은 우선순위 프로세스들 suspend
}
```

1. **비정상적인 동작 감지**:

```c
// 무한루프나 과도한 자원 사용 감지
if (process_cpu_time > MAX_CPU_TIME) {
    suspend_process(runaway_process);  // 폭주 프로세스 suspend
    log_error("Process exceeded CPU time limit");
}
```

1. **사용자/관리자 개입**:

```c
# 사용자가 직접 프로세스 일시정지
kill -STOP 1234  # PID 1234 프로세스 suspend

# 작업 관리자에서 "프로세스 일시 중단" 클릭
# → OS가 해당 프로세스를 suspend 상태로 전환
```

이러한 **프로세스 상태 관리 시스템**을 통해 OS는 **제한된 시스템 자원을 효율적으로 관리**하면서 **안정적인 멀티태스킹 환경**을 제공할 수 있다.  

## sleep() 함수의 다층적 동작 원리

### 1. Thread 관점에서의 sleep() 동작

**스레드는 프로세스 내에서 독립적인 실행 흐름**을 가집니다. 하나의 스레드가 `sleep()`을 호출해도 **같은 프로세스의 다른 스레드들은 전혀 영향받지 않습니다**.

```java
Thread thread1 = new Thread(() -> {
    System.out.println("Thread 1 시작");
    Thread.sleep(1000);  // 1초 대기
    System.out.println("Thread 1 종료");  
});

Thread thread2 = new Thread(() -> {
    System.out.println("Thread 2는 계속 실행");
    // sleep() 없이 계속 실행
});
```

**TCB(Thread Control Block)에서는 각 스레드별로 독립적인 상태 관리**가 이루어집니다. Thread 1이 `SLEEPING` 상태가 되어도 Thread 2는 `RUNNING` 상태를 유지합니다.

**핵심은 스레드별 독립성**입니다. 각 스레드는 자신만의 **스택 영역과 레지스터 상태**를 가지고 있어서, 하나가 sleep해도 다른 스레드의 실행에는 전혀 지장이 없습니다. 이는 **멀티스레드 프로그래밍의 가장 큰 장점** 중 하나입니다.

**가구와 세대원 비유**로 설명하면, 한 세대원(스레드)이 개인방에서 잠을 자도 다른 세대원들은 거실이나 다른 공간에서 자유롭게 활동할 수 있는 것과 같습니다.

### 2. Process 관점에서의 sleep() 동작

**프로세스는 여러 스레드를 관리하는 컨테이너** 역할을 합니다. PCB(Process Control Block)에서는 **전체 프로세스의 상태와 각 스레드들의 상태를 종합적으로 관리**합니다.

하나의 스레드가 sleep해도 **프로세스 전체의 상태는 변하지 않습니다**. 왜냐하면 다른 실행 가능한 스레드들이 여전히 존재하기 때문입니다. 프로세스가 `BLOCKED` 상태가 되려면 **모든 스레드가 sleep하거나 I/O 대기 상태**가 되어야 합니다.

**메모리 관점에서 보면** 더욱 흥미롭습니다. sleep한 스레드의 **Stack 영역은 그대로 유지**되고, **Heap, Data, Code 영역은 다른 스레드들이 계속 사용**할 수 있습니다. 즉, 메모리 자원의 공유는 그대로 이루어지면서 실행만 중단되는 것입니다.

**프로세스는 운영체제로부터 할당받은 가상 메모리 공간** 안에서 여러 스레드가 활동하는 무대를 제공합니다. 한 스레드가 잠시 무대에서 내려가도 무대 자체는 그대로 유지되고 다른 스레드들이 계속 공연을 이어갈 수 있습니다.

### 3. CPU 관점에서의 sleep() 동작

**CPU는 물리적으로 제한된 자원**입니다. 8코어 CPU라면 동시에 최대 8개의 스레드만 실제로 실행할 수 있습니다. 하지만 실제로는 수백, 수천 개의 스레드가 시스템에 존재합니다.

**CPU 스케줄러는 이 한정된 자원을 효율적으로 분배**하는 역할을 합니다. 스레드가 `sleep()`을 호출하면 스케줄러는 즉시 "아, 이 스레드는 당분간 CPU가 필요 없구나"라고 판단하고 **해당 CPU 코어를 다른 대기 중인 스레드에게 할당**합니다.

**시분할 시스템의 핵심**은 여기에 있습니다. 각 스레드가 10ms씩 CPU를 사용한다면, sleep하는 스레드는 자발적으로 자신의 시간을 포기하고 다른 스레드에게 기회를 양보하는 것입니다.

**컨텍스트 스위칭**이 이때 발생합니다. sleep하는 스레드의 레지스터 상태를 TCB에 저장하고, 다음에 실행할 스레드의 상태를 레지스터에 복원합니다. 이 과정은 마이크로초 단위로 이루어지지만, 시스템 전체의 효율성을 크게 높입니다.

### 4. Timer Interrupt와 깨우기 메커니즘

**운영체제는 하드웨어 타이머를 이용해 주기적으로 인터럽트**를 발생시킵니다. 보통 1ms마다 발생하는 이 인터럽트는 시스템의 심장박동과 같습니다.

**타이머 인터럽트가 발생할 때마다** 운영체제는 두 가지 중요한 작업을 수행합니다:

1. **Sleep Queue 검사**: 깨워야 할 시간이 된 스레드들을 찾아서 Ready Queue로 이동
2. **Time Slice 관리**: 현재 실행 중인 스레드의 할당 시간이 끝났는지 확인

**Sleep Queue는 시간 순으로 정렬**되어 있어서 효율적으로 관리됩니다. 가장 앞에 있는 스레드의 깨어날 시간만 확인하면 되고, 그 시간이 아직 안 되었다면 뒤의 스레드들도 모두 아직 시간이 안 된 것입니다.

**정확한 시간에 깨어나는 것은 보장되지 않습니다**. 타이머 인터럽트는 1ms마다 발생하므로 최대 1ms의 오차가 있을 수 있고, 깨어나더라도 Ready Queue에서 대기해야 하므로 추가 지연이 발생할 수 있습니다.

### 5. 전체적인 sleep() 실행 흐름

**Java에서 Thread.sleep() 호출 시 전체 흐름**을 단계별로 살펴보겠습니다:

**1단계: User Mode에서 호출**
Java 애플리케이션에서 `Thread.sleep(1000)`을 호출합니다. 이는 사용자 모드에서 실행되는 일반적인 메서드 호출입니다.

**2단계: JVM 내부 처리**

JVM은 이 호출을 받아서 내부적으로 네이티브 메서드를 호출합니다. JVM의 스레드 관리자가 현재 스레드의 상태를 확인하고 sleep 요청을 준비합니다.

**3단계: System Call 진입**
JVM은 운영체제의 `nanosleep()` 시스템 콜을 호출합니다. 이때 **User Mode에서 Kernel Mode로 전환**이 발생합니다. 이 전환은 특별한 CPU 명령어(x86에서는 `syscall`)를 통해 이루어집니다.

**4단계: Kernel Mode에서 처리**
커널은 시스템 콜을 받아서 다음 작업들을 수행합니다:

- 현재 스레드의 컨텍스트(레지스터 상태)를 TCB에 저장
- 스레드 상태를 `RUNNING`에서 `SLEEPING`으로 변경
- Ready Queue에서 해당 스레드를 제거
- Sleep Queue에 깨어날 시간과 함께 추가
- 다음에 실행할 스레드를 스케줄러가 선택
- 선택된 스레드로 컨텍스트 스위칭 수행

**5단계: 다른 스레드 실행**
CPU는 이제 완전히 다른 스레드를 실행합니다. sleep한 스레드는 메모리에는 존재하지만 CPU 자원은 전혀 사용하지 않습니다.

**6단계: Timer Interrupt 발생**
1ms마다 발생하는 타이머 인터럽트에서 커널은 Sleep Queue를 확인합니다. 깨어날 시간이 된 스레드를 발견하면 Ready Queue로 이동시킵니다.

**7단계: 재스케줄링과 복귀**
Ready Queue에 들어간 스레드는 스케줄러의 선택을 받아 다시 CPU를 할당받습니다. 이때 저장된 컨텍스트가 복원되고, **Kernel Mode에서 User Mode로 복귀**하여 sleep() 호출 다음 줄부터 실행을 재개합니다.

### 6. 메모리와 성능 관점에서의 특징

**메모리 관점에서 sleep()은 매우 효율적**입니다. 실행이 중단되어도 해당 스레드의 메모리는 그대로 유지되고, 다른 스레드들이 공유 메모리(Heap, Data 영역)에 자유롭게 접근할 수 있습니다.

**하지만 성능적으로는 주의해야 할 점들**이 있습니다:

**컨텍스트 스위칭 비용**: sleep() 호출과 깨어날 때 각각 한 번씩, 총 두 번의 컨텍스트 스위칭이 발생합니다. 이는 수천 개의 CPU 사이클을 소모하는 상당한 비용입니다.

**캐시 무효화**: 다른 스레드가 CPU를 사용하면서 L1, L2 캐시의 내용이 바뀝니다. sleep한 스레드가 깨어나면 캐시 미스가 많이 발생할 수 있습니다.

**스케줄링 지연**: Ready Queue에서 대기하는 시간은 예측할 수 없습니다. 1ms sleep을 요청해도 실제로는 수십 ms가 걸릴 수 있습니다.

### 7. 실제 시스템에서의 동작 차이

**Linux에서는** 스레드를 경량 프로세스(LWP)로 구현하므로, 각 스레드가 독립적인 스케줄링 단위가 됩니다. sleep()한 스레드는 완전히 스케줄링에서 제외됩니다.

**Windows에서는** 스레드가 기본 스케줄링 단위이므로 더 직접적으로 관리됩니다. Sleep() API는 커널의 타이머 객체를 이용해 구현됩니다.

**멀티코어 환경에서는** 각 코어가 독립적으로 스케줄링을 수행할 수 있어서, 하나의 코어에서 스레드가 sleep해도 다른 코어들은 전혀 영향받지 않습니다.

이러한 **복잡한 상호작용을 통해 sleep() 함수는 단순해 보이지만 실제로는 운영체제의 핵심 기능들이 모두 동원되는 정교한 메커니즘**입니다. Thread, Process, CPU 각 계층에서의 역할이 조화롭게 어우러져 효율적인 멀티태스킹 환경을 만들어냅니다.


## Process의 생성과 복사

### 프로세스의 접근 제어와 권한 공유

**OS가 자원에 대한 접근을 제어할 때는 프로세스 단위로 접근을 제어**합니다. 이는 보안과 안정성을 위한 핵심 원칙입니다. **프로세스에 특정 자원에 대한 권한이 주어지면 프로세스에 속한 모든 스레드들은 그 권한을 공유**합니다.

```
🏠 프로세스 (가구 단위로 권한 관리)
┌─────────────────────────────────────────────────────┐
│  📁 파일 접근 권한: READ/WRITE                      │
│  🌐 네트워크 권한: 80포트 접근 가능                  │
│  🖥️ 하드웨어 권한: 그래픽카드 사용 가능               │
│                                                     │
│  👨 스레드1   👩 스레드2   👦 스레드3               │
│   ↓           ↓           ↓                        │
│  동일한       동일한       동일한                    │
│  권한 공유    권한 공유    권한 공유                  │
└─────────────────────────────────────────────────────┘
```

예를 들어, 웹 브라우저 프로세스가 특정 파일에 대한 읽기 권한을 받으면 해당 프로세스 내의 모든 스레드(UI 스레드, 네트워크 스레드, 렌더링 스레드 등)가 그 파일을 읽을 수 있습니다. 이는 **권한 관리의 복잡성을 줄이고 일관성을 보장**하는 중요한 설계 원칙입니다.

하지만 이런 권한 공유 방식은 **보안상 위험**도 내포합니다. 한 스레드가 악성 코드에 감염되면 해당 프로세스의 모든 권한을 악용할 수 있기 때문입니다. 그래서 최소 권한 원칙(Principle of Least Privilege)이 중요합니다.

**프로세스에 할당된 가상 메모리 공간은 독립적인 공간으로 보장**받습니다. 이는 각 프로세스가 다른 프로세스의 메모리에 접근할 수 없다는 의미로, 시스템의 안정성과 보안을 확보하는 중요한 메커니즘입니다.

```
🏘️ 운영체제 관리 영역
┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐
│   프로세스 A     │  │   프로세스 B     │  │   프로세스 C     │
│                 │  │                 │  │                 │
│ ┌─────────────┐ │  │ ┌─────────────┐ │  │ ┌─────────────┐ │
│ │독립적인     │ │  │ │독립적인     │ │  │ │독립적인     │ │
│ │가상메모리   │ │  │ │가상메모리   │ │  │ │가상메모리   │ │
│ │공간        │ │  │ │공간        │ │  │ │공간        │ │
│ └─────────────┘ │  │ └─────────────┘ │  │ └─────────────┘ │
│                 │  │                 │  │                 │
│      🚫←→🚫      │  │      🚫←→🚫      │  │      🚫←→🚫      │
└─────────────────┘  └─────────────────┘  └─────────────────┘
     서로 접근 불가        서로 접근 불가        서로 접근 불가
```

이런 **메모리 격리는 하드웨어 차원에서 지원**됩니다. MMU(Memory Management Unit)가 각 프로세스의 페이지 테이블을 통해 가상 주소를 물리 주소로 변환하면서, 다른 프로세스의 메모리 영역에 접근하려 하면 **페이지 폴트 예외**를 발생시킵니다.

### 새로운 프로세스 생성과 메모리 할당

**새로운 프로세스가 생성될 때마다**(새로운 프로그램을 실행할 때) **OS는 새롭게 생성되는 프로세스에게 가상 메모리 공간을 할당**해야 합니다. 이는 상당한 비용이 드는 작업입니다.

```
💻 프로그램 실행 요청
        ↓
┌─────────────────────────────────────┐
│       OS 메모리 관리자              │
│                                     │
│  1️⃣ 새로운 VMS 공간 할당           │
│     ┌─────────────────────────┐    │
│     │     가상 메모리 공간     │    │
│     │  ┌─────┬─────┬─────┐   │    │
│     │  │Stack│Heap │Code │   │    │
│     │  └─────┴─────┴─────┘   │    │
│     └─────────────────────────┘    │
│                                     │
│  2️⃣ PCB 생성 및 초기화             │
│     ┌─────────────────────────┐    │
│     │    Process Control      │    │
│     │         Block           │    │
│     │   PID: 1234            │    │
│     │   State: NEW           │    │
│     └─────────────────────────┘    │
│                                     │
│  3️⃣ 페이지 테이블 설정             │
│  4️⃣ 메모리 맵핑 구성               │
└─────────────────────────────────────┘
```

새로운 가상 메모리 공간을 할당한다는 것은 단순히 메모리만 주는 것이 아닙니다. **페이지 테이블 생성, 메모리 맵 설정, 세그먼트 등록** 등 복잡한 메모리 관리 작업들이 모두 포함됩니다.

**가상 메모리 공간 할당 과정**은 다음과 같습니다:

- **주소 공간 예약**: 4GB(32비트) 또는 수십 TB(64비트)의 가상 주소 공간 할당
- **페이지 테이블 초기화**: 가상 주소와 물리 주소를 매핑할 테이블 생성
- **세그먼트 설정**: 코드, 데이터, 스택 영역의 접근 권한과 크기 설정
- **메모리 보호 설정**: 각 영역별 읽기/쓰기/실행 권한 설정

이 과정에서 **실제 물리 메모리는 즉시 할당되지 않습니다**. Demand Paging 기법을 사용해서 실제로 접근할 때 물리 메모리를 할당합니다. 이는 메모리 사용량을 최적화하는 중요한 기법입니다.

### 부모-자식 프로세스 관계

**어떤 프로세스가 있을 때 이 프로세스는 자신만의 PCB와 VMS(Virtual Memory Space)를 가집니다**. 이때 **이 프로세스가 새로운 프로세스를 생성한다면 원래 있던 프로세스를 부모 프로세스, 생성된 프로세스를 자식 프로세스**라고 합니다.

```
🌳 프로세스 트리 구조
                    init (PID: 1)
                         │
            ┌────────────┼────────────┐
            │            │            │
        systemd      kernel         ...
        (PID: 2)    threads
            │
        ┌───┼───┐
        │   │   │
      bash ssh  Apache
    (PID:100)    (PID: 200)
        │            │
    ┌───┼───┐    ┌───┼───┐
    │   │   │    │   │   │
   vim  ls  cat  worker worker
               threads threads

부모 프로세스 → 자식 프로세스 (권한 상속)
```

이런 관계는 **트리 구조**를 형성합니다. 시스템이 부팅될 때 가장 먼저 생성되는 `init` 프로세스(Linux) 또는 `System` 프로세스(Windows)가 루트가 되고, 모든 프로세스는 이들의 후손이 됩니다.

**부모-자식 관계의 중요한 특징들**:

- **권한 상속**: 자식 프로세스는 부모의 권한을 기본적으로 상속받습니다
- **환경 변수 상속**: PATH, HOME 등의 환경 변수가 자식에게 전달됩니다
- **파일 디스크립터 상속**: 열린 파일들에 대한 접근 권한이 공유됩니다
- **신호 처리**: 부모가 종료되면 자식에게 SIGTERM 신호가 전달됩니다

하지만 **메모리 공간은 독립적**입니다. 부모와 자식이 각자의 가상 메모리 공간을 가지므로 서로의 변수나 데이터에 직접 접근할 수 없습니다.

### Windows vs UNIX 계열의 프로세스 생성 방식

**Windows에서는 createProcess()**, **UNIX 계열에서는 fork()와 exec() 이렇게 2개의 함수가 존재**합니다. 이 차이는 두 운영체제의 설계 철학을 보여줍니다.

```
🪟 Windows 방식
┌─────────────────────────────────────┐
│          createProcess()            │
│                                     │
│  부모 프로세스                       │
│       ↓                            │
│  ┌─────────────┐                   │
│  │ 한 번의 호출 │                   │
│  └─────────────┘                   │
│       ↓                            │
│  새로운 프로세스 + 프로그램 실행      │
│  ┌─────────────────────────────┐   │
│  │  💻 notepad.exe 실행         │   │
│  │  🏠 독립적인 메모리 공간      │   │
│  │  📝 PCB 생성               │   │
│  └─────────────────────────────┘   │
└─────────────────────────────────────┘

🐧 UNIX 방식 (2단계 접근)
┌─────────────────────────────────────┐
│            fork() + exec()          │
│                                     │
│  부모 프로세스                       │
│       ↓ fork()                     │
│  ┌─────────────┐                   │
│  │ 완전한 복사  │                   │
│  └─────────────┘                   │
│       ↓                            │
│  똑같은 두 프로세스                  │
│  ┌─────────┐  ┌─────────┐          │
│  │  부모    │  │  자식    │          │
│  │ (원본)   │  │ (복사본) │          │
│  └─────────┘  └─────────┘          │
│                    ↓ exec()         │
│               새로운 프로그램으로    │
│                    교체             │
│               ┌─────────┐          │
│               │ 새 프로그램│          │
│               └─────────┘          │
└─────────────────────────────────────┘
```

- Windows의 createProcess()는 한 번의 호출로 새로운 프로세스를 생성하고 원하는 프로그램을 실행시킵니다. 이는 **직관적이고 간단한 방식**입니다. 하지만 프로세스 생성과 프로그램 실행이 **원자적(atomic)으로 결합**되어 있어서 중간 단계에서 세밀한 제어가 어렵습니다.
- UNIX의 fork()와 exec()는 프로세스 생성과 프로그램 실행을 분리한 접근법입니다. 이는 **더 유연하지만 이해하기 복잡한 방식**입니다. 하지만 이 분리된 접근법 덕분에 **파이프라인, 리다이렉션, 백그라운드 실행** 등의 고급 기능을 우아하게 구현할 수 있습니다.

### 프로세스 복사의 메커니즘

**프로세스의 복사는 하나의 프로세스가 생성되고 이를 메모리에 복사하는 과정**입니다. 이때 **실행 코드가 복사되고 이에 따른 PCB가 생성**됩니다. **이 시점에 이미 복사된 프로세스에 메모리가 할당**됩니다.

프로세스 복사는 단순한 메모리 복사가 아닙니다. **가상 메모리 맵핑, 페이지 테이블 설정, 파일 디스크립터 복사, 시그널 핸들러 설정** 등 수많은 작업이 함께 이루어집니다.

**실행 파일 형식도 중요한 역할**을 합니다. **C/C++로 실행 파일을 만들 때 UNIX 계열은 a.out ELF 형식 파일이, Windows는 a.exe PE 포맷 형식의 파일**이 만들어집니다.

```
📁 실행 파일 형식 비교

🐧 UNIX/Linux (ELF - Executable and Linkable Format)
┌─────────────────────────────────┐
│            a.out                │
│  ┌─────────────────────────┐   │
│  │      ELF Header         │   │ ← 파일 기본 정보
│  ├─────────────────────────┤   │
│  │   Program Header Table  │   │ ← 실행 시 메모리 구성
│  ├─────────────────────────┤   │
│  │      .text section      │   │ ← 실행 코드 (복사 대상)
│  ├─────────────────────────┤   │
│  │      .data section      │   │ ← 초기화된 데이터
│  ├─────────────────────────┤   │
│  │      .bss section       │   │ ← 초기화되지 않은 데이터
│  ├─────────────────────────┤   │
│  │   Section Header Table  │   │ ← 섹션 정보
│  └─────────────────────────┘   │
└─────────────────────────────────┘

🪟 Windows (PE - Portable Executable)
┌─────────────────────────────────┐
│            a.exe                │
│  ┌─────────────────────────┐   │
│  │      DOS Header         │   │ ← 호환성을 위한 헤더
│  ├─────────────────────────┤   │
│  │      PE Header          │   │ ← PE 파일 정보
│  ├─────────────────────────┤   │
│  │   Optional Header       │   │ ← 실행 정보
│  ├─────────────────────────┤   │
│  │    .text section        │   │ ← 실행 코드 (복사 대상)
│  ├─────────────────────────┤   │
│  │    .data section        │   │ ← 초기화된 데이터
│  ├─────────────────────────┤   │
│  │    .rdata section       │   │ ← 읽기 전용 데이터
│  └─────────────────────────┘   │
└─────────────────────────────────┘
```

**PE 포맷을 뜯어보면 header section이 존재**하고 **생성하고 복사할 때 이 section 영역의 text 영역을 복사**합니다. 이 `.text` 섹션에는 **실제 실행 가능한 기계어 코드**가 들어있습니다.

프로세스 로더는 이 섹션 정보를 읽어서 **각 섹션을 메모리의 적절한 위치에 매핑**합니다. `.text` 섹션은 읽기+실행 권한으로, `.data` 섹션은 읽기+쓰기 권한으로 매핑됩니다. 이렇게 **프로세스의 생성이 매우 복잡한 과정**입니다.

### fork()와 exec()의 차이점과 동작 원리

**fork()와 exec()의 차이점을 이해하는 것은 UNIX 철학의 핵심**입니다.

```
🔄 fork() 과정 (Ctrl+C → Ctrl+V 와 유사)

실행 전:
┌─────────────────┐
│   부모 프로세스   │
│   PID: 100      │
│  ┌─────────────┐│
│  │   메모리     ││
│  │ ┌─────────┐ ││
│  │ │ Stack   │ ││
│  │ │ Heap    │ ││
│  │ │ Data    │ ││
│  │ │ Code    │ ││
│  │ └─────────┘ ││
│  └─────────────┘│
└─────────────────┘

fork() 호출 후:
┌─────────────────┐    ┌─────────────────┐
│   부모 프로세스   │    │   자식 프로세스   │
│   PID: 100      │    │   PID: 101      │
│  ┌─────────────┐│    │  ┌─────────────┐│
│  │   메모리     ││    │  │   메모리     ││
│  │ ┌─────────┐ ││    │  │ ┌─────────┐ ││
│  │ │ Stack   │ ││    │  │ │ Stack   │ ││
│  │ │ Heap    │ ││    │  │ │ Heap    │ ││
│  │ │ Data    │ ││    │  │ │ Data    │ ││
│  │ │ Code    │ ││ 📋 │  │ │ Code    │ ││
│  │ └─────────┘ ││복사 │  │ └─────────┘ ││
│  └─────────────┘│    │  └─────────────┘│
└─────────────────┘    └─────────────────┘
      동일한 내용           동일한 내용
```

**fork()는 부모 프로세스의 완전한 복사본**을 만듭니다. **부모 프로세스에 대한 모든 정보를 복사하는 것으로, 마치 Ctrl+C 후 Ctrl+V 한 것과 유사**합니다. **복사한 다음에 register 정보만 초기화해서 완전히 새로운 코드를 사용할 수 있게** 됩니다.

fork() 호출 후에는 **두 개의 동일한 프로세스**가 존재하게 됩니다. 부모와 자식은 같은 코드를 실행하지만 서로 다른 메모리 공간을 가집니다. 이때 **Copy-On-Write(COW) 기법**을 사용해서 실제로는 메모리를 즉시 복사하지 않고, 수정이 발생할 때만 복사합니다.

**fork()의 반환값으로 부모와 자식을 구분**합니다:

- **부모 프로세스**: 자식의 PID (양수) 반환
- **자식 프로세스**: 0 반환
- **오류 발생시**: -1 반환

```
🔄 exec() 과정 (기존 프로세스 덮어쓰기)

exec() 호출 전:
┌─────────────────┐
│   현재 프로세스   │
│   PID: 101      │
│  ┌─────────────┐│
│  │ 기존 프로그램 ││
│  │ ┌─────────┐ ││
│  │ │old_code │ ││
│  │ │old_data │ ││
│  │ └─────────┘ ││
│  └─────────────┘│
└─────────────────┘

exec() 호출 후:
┌─────────────────┐
│   같은 프로세스   │
│   PID: 101      │ ← PID는 그대로
│  ┌─────────────┐│
│  │ 새로운 프로그램││
│  │ ┌─────────┐ ││
│  │ │new_code │ ││ ← 내용만 교체
│  │ │new_data │ ││
│  │ └─────────┘ ││
│  └─────────────┘│
└─────────────────┘
```

**exec()는 완전히 다른 접근법**입니다. **부모 프로세스가 곧 종료된다면 이렇게 복잡하게 VMS + PCB에 기타 OS에서 하는 작업을 한 번 다 할 필요 없이, 곧 종료될 부모 프로세스에 코드만 새롭게 추가해서 실행시키자**는 것이 exec()의 아이디어입니다. **기존 코드에 새로운 코드를 덮어쓰는 방식**입니다.

exec() 계열 함수들에는 여러 변형이 있습니다:

- **execl()**: 인자를 리스트로 전달
- **execv()**: 인자를 배열로 전달
- **execle()**: 환경변수도 함께 전달
- **execve()**: 가장 기본적인 시스템 콜

**exec() 호출이 성공하면 원래 프로그램으로 돌아오지 않습니다**. 완전히 새로운 프로그램으로 교체되기 때문입니다.

```
📊 생성 방향 비교

fork() 방식:
부모 프로세스 ────┐
                 │ 새로운 자식 생성
                 ↓
              자식 프로세스
         (Parent → new Child)

exec() 방식:
기존 프로세스 ────┐
                 │ 자신을 새 프로그램으로 교체
                 ↓
              변경된 프로세스
         (Parent ← new Child)
```

**프로세스 생성 방향의 차이**:

- **fork()**: Parent → new Child (부모가 자식을 생성)
- **exec()**: Parent ← new Child (자식이 부모를 대체)

### 프로세스 대기와 종료 메커니즘

**프로세스 간의 동기화를 위해 대기 함수들이 존재**합니다. **Windows는 waitForSingleObject(), UNIX는 wait()**가 있습니다.

**이 함수들은 호출 시 대기 상태로 변경**되어서 **보통 프로세스 레벨 단위로 하지 않고 스레드를 하나 생성해서 스레드 단위로 호출**됩니다. 이는 전체 프로세스가 블로킹되는 것을 방지하기 위함입니다.

```
🧵 스레드 기반 프로세스 대기

메인 프로세스
┌─────────────────────────────────────┐
│  🧵 메인 스레드 (계속 실행)          │
│     ├─ UI 처리                      │
│     ├─ 사용자 입력 처리              │
│     └─ 기타 작업                    │
│                                     │
│  🧵 대기 전용 스레드                 │
│     ├─ waitForSingleObject()       │ ← Windows
│     │   또는 wait()                 │ ← UNIX
│     ├─ 자식 프로세스 종료 대기       │
│     └─ 종료 시 콜백 실행             │
│                                     │
│  자식 프로세스 ────────┐            │
│  ┌─────────────────┐  │            │
│  │     실행 중      │  │            │
│  └─────────────────┘  │            │
│           │           │            │
│           ↓ 종료      │            │
│  ┌─────────────────┐  │            │
│  │   exit() 호출    │──┘            │
│  └─────────────────┘               │
│           │                        │
│           ↓ 신호 전달                │
│     대기 스레드 깨어남               │
└─────────────────────────────────────┘
```

만약 메인 스레드에서 `wait()`을 호출하면 자식 프로세스가 종료될 때까지 전체 프로세스가 멈춰버립니다. 따라서 **별도의 워커 스레드를 만들어서 그 스레드에서만 대기**하도록 하는 것이 일반적인 패턴입니다.

**UNIX의 wait() 계열 함수들**:

- **wait()**: 아무 자식이나 종료될 때까지 대기
- **waitpid()**: 특정 자식 프로세스가 종료될 때까지 대기
- **waitid()**: 더 세밀한 제어가 가능한 대기 함수

**Windows의 대기 함수들**:

- **WaitForSingleObject()**: 하나의 객체(프로세스, 스레드, 이벤트 등) 대기
- **WaitForMultipleObjects()**: 여러 객체를 동시에 대기
- **WaitForSingleObjectEx()**: 알림 가능한 대기 상태

**프로세스 종료를 위해서는 exitProcess()와 exit() 함수**가 사용됩니다. **exit()는 현재 프로세스만 종료**하지만, **exitProcess()는 프로세스 전체를 강제로 종료**시킵니다.

**종료 함수들의 차이**:

- **exit()**: 정상적인 종료, cleanup 함수들 호출
- **_exit()**: 즉시 종료, cleanup 생략
- **abort()**: 비정상 종료, 코어 덤프 생성