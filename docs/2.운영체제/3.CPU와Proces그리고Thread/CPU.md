# CPU

## CPU도 당신처럼 예측하고 미리 움직인다.
  
![img_2.png](../../static/img_2.png)  

### CPU 성능 향상의 변화

CPU는 연산 장치이고 속도가 빠를수록 처리량이 늘어나게 된다. 이전에는 **클럭을 증가**시켜서 성능 향상을 했다면 요즘은 **코어의 개수를 증가**시켜서 CPU 성능을 개선하고 있다.

**핵심 개념 정리**:

- **클럭(Clock)**: CPU가 명령어를 처리하는 주기. 1GHz = 초당 10억 번의 작업 수행
- **코어(Core)**: 실제 연산을 수행하는 독립적인 처리 단위. 4코어 = 4개의 CPU가 병렬 작업
- **레지스터(Register)**: CPU 내부의 가장 빠른 저장공간. 연산에 필요한 데이터를 임시 보관

**클럭 한계와 멀티코어 전환 이유**:

- **발열 문제**: 클럭이 높아질수록 전력 소모와 발열이 기하급수적으로 증가
- **물리적 한계**: 실리콘 기반 반도체의 물리적 한계에 도달 (현재 3-5GHz 수준)
- **병렬 처리**: 멀티코어로 여러 작업을 동시에 처리하는 것이 더 효율적

### 메모리 계층 구조와 속도 차이

CPU의 연산은 **코어**가 담당해서 처리하게 된다. CPU가 처리하게 되는 연산 데이터는 **RAM에 존재하는 데이터를 CPU 영역까지 옮기고 → 처리하고 → 다시 RAM에 쓰는** 일련의 과정을 반복한다.

이때 코어 안에 있는 CPU 내부 저장장치인 **레지스터의 속도와 RAM의 속도 차이**가 크게 발생한다.

**실제 속도 차이** (대략적 접근 시간):

```
레지스터:    1 cycle      (기준)
L1 캐시:     2-4 cycle    (2-4배 느림)
L2 캐시:     10-20 cycle  (10-20배 느림)  
L3 캐시:     20-40 cycle  (20-40배 느림)
RAM:         100-300 cycle (100-300배 느림)
```

일반적으로 우리보다 **100배 느리게 말하는 사람**과 정상적인 소통을 하기가 쉽지 않다. 그래서 이를 보완하기 위해서 **완충지대**를 만들었는데 그것이 **캐시 메모리**이다.

**계층별 역할**:

- **RAM**: 외부 장치인 SSD/HDD와의 완충 역할
- **캐시 메모리**: CPU 레지스터와 RAM 간의 완충 역할

즉, **캐시 메모리의 가장 큰 역할은 RAM과 레지스터의 속도 차이 극복**에 있다.

### 캐시 메모리 구조

CPU 제조사마다 L1과 L2의 차이가 있지만 보통은 아래처럼 구성되어 있다:

```
Core 0      Core 1        Core 2      Core 3
------      ------        ------      ------
L1I L1D     L1I L1D       L1I L1D     L1I L1D  ← 명령어/데이터 분리
------      ------        ------      ------
  L2          L2            L2          L2     ← 명령어/데이터 통합
--------------------------------------------------
                    L3 (Shared)                ← 모든 코어 공유
```

**캐시 레벨별 특징**:

- **L1 (Level 1)**: 명령어(Instruction)와 데이터(Data)가 **분리**되어 있음
    - L1I: 명령어 캐시 (32-64KB)
    - L1D: 데이터 캐시 (32-64KB)
- **L2 (Level 2)**: 명령어와 데이터가 **혼합**되어 있음 (256KB-1MB)
- **L3 (Level 3)**: **코어 전반적으로 공유**할 데이터들을 보관 (8-32MB)

### CPU의 예측 기능 (Branch Prediction & Prefetching)

CPU 연산이라 하면 **명령어에 대한 처리**이고, 이 명령에 필요한 **데이터는 캐시 메모리에서 가져오게** 된다. 그러면 이 **예측이라는 작업은 캐시 메모리에서 일어나는** 것이다.

**예측 시나리오 예시**:

```java
for(int i = 0; i < 100; i++){
    intArray[i] = 연산작업;
}
```

이런 작업이 있을 때 CPU는:

1. **i라는 변수가 0부터 100까지 순차적으로 증가**한다는 패턴 인식
2. **100보다 작을 때까지 반복**한다는 분기 예측
3. **배열 크기가 100개 정도 될 것**이라는 데이터 예측
4. **미리 이 배열 데이터를 캐시 메모리에 가져다 두고** 처리

**구체적인 예측 메커니즘**:

- **Branch Predictor**: 조건문(if, for, while)의 결과를 미리 예측
- **Prefetcher**: 순차적 메모리 접근 패턴을 감지하여 다음 데이터 미리 로드
- **Spatial Locality**: 현재 접근한 메모리 근처 데이터도 함께 캐시에 로드
- **Temporal Locality**: 최근 사용한 데이터를 캐시에 오래 보관

### 캐시 동작 과정

**CPU 데이터 요청 순서**:

1. CPU가 연산을 할 때 **바로 RAM에게 데이터를 요구하지 않고**
2. **먼저 캐시 메모리에게 필요한 정보를 요청**
3. CPU가 미리 예측해서 해당 데이터를 캐시 메모리에 옮겨두었으면
4. **RAM과 I/O 작업을 하지 않고 빠르게 해당 작업을 처리**

**일상생활 비유**:
마치 **연구원과 조수**가 있는데 어떤 연구를 진행하고 있다고 가정했을 때, 조수가 미리 특정 자료가 필요할 것 같아서 **도서관에 가서 미리 빌려서** 가지고 있었고, 연구원이 해당 자료를 요청했을 때 **사전에 필요할 것 같아서 빌려둔 자료를 즉시 전달**하는 것과 유사하다.

### 캐시 성능 지표

**Cache Hit (캐시 적중)**:

- 예측이 성공한 경우
- CPU가 요청한 데이터가 캐시에 존재
- **빠른 처리 속도** 달성

**Cache Miss (캐시 미스)**:

- 예측에 실패한 경우
- **L1 → L2 → L3 → RAM** 순으로 계층적 탐색
- **성능 저하** 발생

**실제 성능 영향**:

```
Cache Hit Rate 95% vs 90%의 차이:
- 전체 성능: 약 2-3배 차이
- 게임/멀티미디어: 체감 성능 차이 크게 발생
- 서버 애플리케이션: 처리량 현저한 차이
```

**캐시 최적화 프로그래밍 기법**:

- **순차 접근**: 배열을 순서대로 접근 (Spatial Locality 활용)
- **블록 단위 처리**: 데이터를 캐시 라인 크기(64바이트)로 맞춰 처리
- **루프 최적화**: 내부 루프가 캐시에 맞도록 크기 조정

이러한 **CPU의 예측 기능과 캐시 메모리 시스템**은 현대 고성능 컴퓨팅의 핵심이며, 소프트웨어 개발 시에도 이를 고려한 **캐시 친화적 프로그래밍**이 성능 최적화의 열쇠가 된다.



### PIM (Processing-In-Memory) - 메모리가 직접 연산하는 새로운 패러다임

**기존 CPU 중심 구조의 한계**:

```
CPU ↔ 캐시 ↔ RAM (데이터만 저장)
     ↑
모든 연산이 CPU로 집중
```

**PIM의 혁신적 아이디어**:

```
CPU ↔ 캐시 ↔ PIM Memory (저장 + 연산)
                    ↑
                기초 연산을 메모리에서 직접 처리
```

### PIM의 핵심 개념

**Processing-In-Memory**는 **메모리 자체에 연산 능력을 내장**하여 데이터를 CPU로 이동시키지 않고 **메모리 내부에서 직접 기초 연산을 처리**하는 기술이다.

**기존 방식의 문제점**:

- **메모리 월(Memory Wall)**: CPU-메모리 간 속도 차이가 계속 벌어짐
- **데이터 이동 비용**: 연산보다 데이터 이동에 더 많은 에너지 소모
- **폰 노이만 병목**: 명령어와 데이터가 같은 버스를 공유하여 발생하는 성능 제약

### PIM의 구현 방식

**1. Near-Data Computing**:

```
RAM Chip 내부에 간단한 프로세서 내장
├─ 기본 연산: 덧셈, 뺄셈, 비교, 논리 연산
├─ 벡터 연산: SIMD 방식의 병렬 처리
└─ 메모리 컨트롤러와 연산 유닛 통합
```

**2. In-Memory Computing**:

```
메모리 셀 자체가 연산 기능 수행
├─ ReRAM (Resistive RAM): 저항 변화로 연산
├─ MRAM (Magnetic RAM): 자기 상태로 연산  
└─ Crossbar Array: 아날로그 연산 수행
```

### 실제 활용 분야와 성능

**AI/머신러닝에서의 혁신**:

```java
// 기존 방식 (비효율적)
for(int i = 0; i < matrix_size; i++) {
    // 1. RAM에서 CPU로 데이터 이동
    // 2. CPU에서 행렬 곱셈 연산  
    // 3. 결과를 다시 RAM으로 이동
    result[i] = matrix_multiply(a[i], b[i]);
}

// PIM 방식 (효율적)
// 메모리 내부에서 직접 행렬 연산 수행
pim_matrix_multiply(matrix_a, matrix_b, result);
// 데이터 이동 없이 메모리에서 연산 완료
```

**대표적인 PIM 제품들**:

- **Samsung HBM-PIM**: 고대역폭 메모리에 연산 기능 추가
- **SK Hynix AiM**: AI 가속을 위한 PIM 메모리
- **Intel/Micron 3D XPoint**: 스토리지 클래스 메모리에 연산 기능

### 성능 향상 효과

**에너지 효율성**:

- **기존**: 데이터 이동에 전체 에너지의 60-80% 소모
- **PIM**: 데이터 이동 최소화로 **5-10배 에너지 절약**

**처리 성능**:

- **AI 추론**: 기존 대비 **2-5배 성능 향상**
- **대용량 데이터 분석**: **10-100배 빠른 집계 연산**
- **그래프 처리**: 메모리 집약적 작업에서 **획기적 성능 개선**

### 미래 전망

**PIM + 기존 CPU 캐시의 협력**:

```
CPU (복잡한 제어 로직) 
 ↕
캐시 (빠른 임시 저장)
 ↕  
PIM Memory (대용량 데이터의 기초 연산)
```

이러한 **PIM 기술**은 특히 **빅데이터, AI, 과학 계산** 분야에서 기존 CPU 중심 아키텍처의 한계를 극복하는 **게임 체인저** 역할을 하고 있으며, 앞으로 **메모리와 연산의 경계가 모호해지는** 새로운 컴퓨팅 시대를 열어가고 있다.