# CPU

## CPU도 당신처럼 예측하고 미리 움직인다.
  
![img_2.png](../../static/img_2.png)  

### CPU 성능 향상의 변화

CPU는 연산 장치이고 속도가 빠를수록 처리량이 늘어나게 된다. 이전에는 **클럭을 증가**시켜서 성능 향상을 했다면 요즘은 **코어의 개수를 증가**시켜서 CPU 성능을 개선하고 있다.

**핵심 개념 정리**:

- **클럭(Clock)**: CPU가 명령어를 처리하는 주기. 1GHz = 초당 10억 번의 작업 수행
- **코어(Core)**: 실제 연산을 수행하는 독립적인 처리 단위. 4코어 = 4개의 CPU가 병렬 작업
- **레지스터(Register)**: CPU 내부의 가장 빠른 저장공간. 연산에 필요한 데이터를 임시 보관

**클럭 한계와 멀티코어 전환 이유**:

- **발열 문제**: 클럭이 높아질수록 전력 소모와 발열이 기하급수적으로 증가
- **물리적 한계**: 실리콘 기반 반도체의 물리적 한계에 도달 (현재 3-5GHz 수준)
- **병렬 처리**: 멀티코어로 여러 작업을 동시에 처리하는 것이 더 효율적

### 메모리 계층 구조와 속도 차이

CPU의 연산은 **코어**가 담당해서 처리하게 된다. CPU가 처리하게 되는 연산 데이터는 **RAM에 존재하는 데이터를 CPU 영역까지 옮기고 → 처리하고 → 다시 RAM에 쓰는** 일련의 과정을 반복한다.

이때 코어 안에 있는 CPU 내부 저장장치인 **레지스터의 속도와 RAM의 속도 차이**가 크게 발생한다.

**실제 속도 차이** (대략적 접근 시간):

```
레지스터:    1 cycle      (기준)
L1 캐시:     2-4 cycle    (2-4배 느림)
L2 캐시:     10-20 cycle  (10-20배 느림)  
L3 캐시:     20-40 cycle  (20-40배 느림)
RAM:         100-300 cycle (100-300배 느림)
```

일반적으로 우리보다 **100배 느리게 말하는 사람**과 정상적인 소통을 하기가 쉽지 않다. 그래서 이를 보완하기 위해서 **완충지대**를 만들었는데 그것이 **캐시 메모리**이다.

**계층별 역할**:

- **RAM**: 외부 장치인 SSD/HDD와의 완충 역할
- **캐시 메모리**: CPU 레지스터와 RAM 간의 완충 역할

즉, **캐시 메모리의 가장 큰 역할은 RAM과 레지스터의 속도 차이 극복**에 있다.

### 캐시 메모리 구조

CPU 제조사마다 L1과 L2의 차이가 있지만 보통은 아래처럼 구성되어 있다:

```
Core 0      Core 1        Core 2      Core 3
------      ------        ------      ------
L1I L1D     L1I L1D       L1I L1D     L1I L1D  ← 명령어/데이터 분리
------      ------        ------      ------
  L2          L2            L2          L2     ← 명령어/데이터 통합
--------------------------------------------------
                    L3 (Shared)                ← 모든 코어 공유
```

**캐시 레벨별 특징**:

- **L1 (Level 1)**: 명령어(Instruction)와 데이터(Data)가 **분리**되어 있음
    - L1I: 명령어 캐시 (32-64KB)
    - L1D: 데이터 캐시 (32-64KB)
- **L2 (Level 2)**: 명령어와 데이터가 **혼합**되어 있음 (256KB-1MB)
- **L3 (Level 3)**: **코어 전반적으로 공유**할 데이터들을 보관 (8-32MB)

### CPU의 예측 기능 (Branch Prediction & Prefetching)

CPU 연산이라 하면 **명령어에 대한 처리**이고, 이 명령에 필요한 **데이터는 캐시 메모리에서 가져오게** 된다. 그러면 이 **예측이라는 작업은 캐시 메모리에서 일어나는** 것이다.

**예측 시나리오 예시**:

```java
for(int i = 0; i < 100; i++){
    intArray[i] = 연산작업;
}
```

이런 작업이 있을 때 CPU는:

1. **i라는 변수가 0부터 100까지 순차적으로 증가**한다는 패턴 인식
2. **100보다 작을 때까지 반복**한다는 분기 예측
3. **배열 크기가 100개 정도 될 것**이라는 데이터 예측
4. **미리 이 배열 데이터를 캐시 메모리에 가져다 두고** 처리

**구체적인 예측 메커니즘**:

- **Branch Predictor**: 조건문(if, for, while)의 결과를 미리 예측
- **Prefetcher**: 순차적 메모리 접근 패턴을 감지하여 다음 데이터 미리 로드
- **Spatial Locality**: 현재 접근한 메모리 근처 데이터도 함께 캐시에 로드
- **Temporal Locality**: 최근 사용한 데이터를 캐시에 오래 보관

### 캐시 동작 과정

**CPU 데이터 요청 순서**:

1. CPU가 연산을 할 때 **바로 RAM에게 데이터를 요구하지 않고**
2. **먼저 캐시 메모리에게 필요한 정보를 요청**
3. CPU가 미리 예측해서 해당 데이터를 캐시 메모리에 옮겨두었으면
4. **RAM과 I/O 작업을 하지 않고 빠르게 해당 작업을 처리**

**일상생활 비유**:
마치 **연구원과 조수**가 있는데 어떤 연구를 진행하고 있다고 가정했을 때, 조수가 미리 특정 자료가 필요할 것 같아서 **도서관에 가서 미리 빌려서** 가지고 있었고, 연구원이 해당 자료를 요청했을 때 **사전에 필요할 것 같아서 빌려둔 자료를 즉시 전달**하는 것과 유사하다.

### 캐시 성능 지표

**Cache Hit (캐시 적중)**:

- 예측이 성공한 경우
- CPU가 요청한 데이터가 캐시에 존재
- **빠른 처리 속도** 달성

**Cache Miss (캐시 미스)**:

- 예측에 실패한 경우
- **L1 → L2 → L3 → RAM** 순으로 계층적 탐색
- **성능 저하** 발생

**실제 성능 영향**:

```
Cache Hit Rate 95% vs 90%의 차이:
- 전체 성능: 약 2-3배 차이
- 게임/멀티미디어: 체감 성능 차이 크게 발생
- 서버 애플리케이션: 처리량 현저한 차이
```

**캐시 최적화 프로그래밍 기법**:

- **순차 접근**: 배열을 순서대로 접근 (Spatial Locality 활용)
- **블록 단위 처리**: 데이터를 캐시 라인 크기(64바이트)로 맞춰 처리
- **루프 최적화**: 내부 루프가 캐시에 맞도록 크기 조정

이러한 **CPU의 예측 기능과 캐시 메모리 시스템**은 현대 고성능 컴퓨팅의 핵심이며, 소프트웨어 개발 시에도 이를 고려한 **캐시 친화적 프로그래밍**이 성능 최적화의 열쇠가 된다.