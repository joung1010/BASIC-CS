## DMA(Direct Memory Access)와 고성능 소켓

### DMA를 알면 고성능 소켓이 보인다

**기본 시스템 구조**

```
CPU + Cache ↔ RAM (예약된 DMA 영역 포함) ↔ I/O Controller ↔ Device
                    ↑
               DMA Controller
```

**I/O 매니저의 역할과 한계**
I/O 매니저의 주 역할은 CPU가 특정 장치에서 데이터를 직접 가져올 때 발생하는 지연 시간 동안 CPU가 다른 작업을 처리할 수 있도록 돕는 것이다.

**전통적인 I/O 처리 과정의 비효율성**:

1. CPU가 데이터를 RAM의 **커널 버퍼(1번 영역)**에 복사
2. 커널이 데이터를 **다른 커널 버퍼(2번 영역)**로 재복사
3. Device가 2번 영역에서 데이터를 읽어감
4. **총 3번의 메모리 복사** 작업 발생 → CPU 자원 낭비

**DMA의 핵심 아이디어**
이렇게 여러 번의 I/O 작업(데이터 복사) 없이 그냥 한 번에 원하는 장치로 직접 접근하면 안 되는 것일까?

- *DMA(Direct Memory Access)**는 **CPU 개입 없이** 메모리와 I/O 장치 간 직접 데이터 전송을 통해 성능을 향상시키는 기술이다. 주로 **NIC(Network Interface Card)**에서 가장 활발하게 사용된다.

### 네트워크 소켓에서의 DMA 활용

**시스템 계층 구조**

```
Process (User Mode)
─────────────────────────────────
Socket Interface (추상화 계층)    ← TCP/IP는 파일이 아닌 소켓
─────────────────────────────────
Kernel Space
├─ Protocol Stack (TCP/IP)
├─ Socket Buffer (SKB)
└─ Network Driver
─────────────────────────────────
Hardware (NIC with DMA)
```

**전통적인 네트워크 송신 과정**

1. 프로세스에서 **송신할 데이터 준비** (User Space Buffer)
2. `send()` 시스템 콜 호출 (소켓이므로 `write()`가 아닌 `send()`)
3. 데이터가 **커널의 Socket Buffer**에 복사
4. 커널에서 데이터를 **패킷으로 분할(Segmentation)**하여 **Driver Buffer**에 복사
5. NIC가 Driver Buffer에서 데이터를 읽어 **네트워크로 전송**
6. **총 3번의 메모리 복사** (User→Kernel→Driver→NIC)

**DMA 기반 최적화 (Zero-Copy)**
NIC가 DMA를 지원하면 **2~4단계를 스킵**하고:

- 네트워크 수신 시: **DMA가 직접 User Mode Heap Memory에 데이터 작성**
- 네트워크 송신 시: **DMA가 직접 User Buffer에서 NIC로 전송**

**운영체제 지원 방식**:

- OS가 해당 메모리 영역에 **페이지 락(Page Lock)** 설정
- 커널이 "이 메모리에 직접 데이터를 쓸 것"이라고 **예약 설정**
- **중간 복사 과정 완전 제거** → **Zero-Copy I/O**

**대표적인 구현 예시**:

- **Windows**: IOCP (I/O Completion Port) + Overlapped I/O
- **Linux**: io_uring, epoll + splice/sendfile
- **FreeBSD**: kqueue + zero-copy sockets

### 실제 성능 차이

**전통적 방식**:

```
// 3번의 메모리 복사 발생
char buffer[1024];
recv(socket, buffer, 1024, 0);  // Kernel→User 복사
// 처리 후
send(socket, buffer, 1024, 0);  // User→Kernel 복사
```

**DMA + Zero-Copy 방식**:

```
// 메모리 복사 없이 직접 DMA 처리
char *dma_buffer = mmap_dma_region(1024);  // DMA 영역 매핑
// DMA가 직접 dma_buffer에 데이터 작성
// 복사 없이 바로 처리 가능
```

**성능 향상**:

- **CPU 사용률**: 50-70% 감소
- **메모리 대역폭**: 2-3배 절약
- **지연 시간**: 30-50% 단축
- **처리량**: 2-5배 향상

### 가상화 환경에서의 DMA 최적화

**가상화 시스템 구조**

```
┌─────────────────┐  ┌─────────────────┐
│   Guest OS      │  │   Guest OS      │
│ ┌─────────────┐ │  │ ┌─────────────┐ │
│ │User Process │ │  │ │User Process │ │
│ └─────────────┘ │  │ └─────────────┘ │
│ ┌─────────────┐ │  │ ┌─────────────┐ │
│ │Guest Kernel │ │  │ │Guest Kernel │ │
│ └─────────────┘ │  │ └─────────────┘ │
│     (West)      │  │     (East)      │
└─────────────────┘  └─────────────────┘
──────────────────────────────────────────
│         Hypervisor (VMM)              │
│    ┌─────────────────────────────┐    │
│    │    Shared Memory Pool       │    │
│    └─────────────────────────────┘    │
──────────────────────────────────────────
│          Host Hardware               │
│              Physical RAM             │
└──────────────────────────────────────────
```

**가상화 환경의 DMA 최적화 원리**
가상화 Guest OS들은 결국 **물리적인 동일한 RAM** 어딘가에 존재한다. West VM에서 East VM으로 네트워크 통신 시:

**전통적 방식**:

```
West VM → Guest OS Network Stack → Hypervisor → 
Virtual Network → Hypervisor → Guest OS Network Stack → East VM
```

**DMA + Shared Memory 최적화**:

```
West VM → Shared Memory Pool → East VM
(직접 RAM 복사, 네트워크 스택 완전 우회)
```

**구현 기술들**:

- **DPDK (Data Plane Development Kit)**: 사용자 공간에서 직접 NIC 제어
- **SR-IOV**: 물리 NIC를 여러 가상 함수로 분할하여 VM이 직접 접근
- **VFIO (Virtual Function I/O)**: VM이 물리 장치에 직접 DMA 접근
- **Shared Memory Communications (SMC)**: 동일 물리 서버 내 VM 간 메모리 직접 공유

**성능 혜택**:

- **네트워크 지연**: 마이크로초 → 나노초 단위
- **처리량**: 기존 대비 10-100배 향상
- **CPU 오버헤드**: 90% 이상 감소
- **컨테이너 간 통신**: 메모리 복사 속도로 처리

### 실무 구현 고려사항

**DMA 사용 시 주의점**:

1. **메모리 정렬**: DMA는 특정 바이트 경계에 정렬된 메모리만 접근 가능
2. **캐시 일관성**: CPU 캐시와 DMA 메모리 간 동기화 필요
3. **메모리 고정**: DMA 중인 메모리는 스와핑되면 안 됨
4. **권한 관리**: 커널 영역 메모리에 대한 직접 접근 권한 제어

**최적화 기법들**:

- **Ring Buffer**: 순환 버퍼로 연속적인 DMA 처리
- **Scatter-Gather DMA**: 분산된 메모리 영역을 하나의 전송으로 처리
- **Interrupt Coalescing**: 여러 DMA 완료를 한 번의 인터럽트로 처리

이러한 DMA 기술은 **고성능 네트워크 애플리케이션, 실시간 시스템, 대용량 데이터 처리** 시스템에서 필수적인 최적화 기법이 되었다.