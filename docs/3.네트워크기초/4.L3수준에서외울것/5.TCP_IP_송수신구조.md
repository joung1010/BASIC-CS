### TCP/IP 송수신 구조

### 에펠탑 택배 비유를 통한 기본 개념

**파리에서 에펠탑을 택배로 보내려면 어떻게 해야 할까?**

**먼저 첫 번째로 에펠탑을 분해를 해서 크기를 줄여야 합니다. 어느 크기까지 분해를 해야 한다고 하면 운송이 가능할 정도의 크기로 분해해야 합니다. 즉 MTU 이하로 줄여야 됩니다.**

**그다음 두 번째로는 운송을 하면 됩니다.**

**그리고 세 번째로는 전달받은 택배를 조립하면 됩니다.**

```
에펠탑 택배 vs TCP/IP 통신:

에펠탑 배송:
┌─────────────────────────────────────────┐
│ 1. 분해: 에펠탑 → 운송 가능한 크기      │
│ 2. 운송: 여러 트럭으로 나누어 배송      │
│ 3. 조립: 목적지에서 원래 모습으로 복원  │
└─────────────────────────────────────────┘

TCP/IP 통신:
┌─────────────────────────────────────────┐
│ 1. 분해: 1.4MB 파일 → MTU 크기 패킷들   │
│ 2. 운송: 인터넷을 통해 패킷별 전송      │
│ 3. 조립: 수신 측에서 원본 파일 복원     │
└─────────────────────────────────────────┘
```

**여기서 이 분해라는 작업은 송신 측에서 하게 될 것이고 조립은 수신 측에서 하게 됩니다.**

### 전체 네트워크 구조와 데이터 흐름

### 네트워크 경로와 패킷 전송

```
전체 네트워크 구조:

PC → L2 Access Switch → 라우터 → 인터넷 → 라우터 → L2 Access Switch → 서버
   ←                 ←        ←        ←       ←                  ←  
              ← 패킷 형태의 데이터 (양방향) →
```

**어떤 PC가 L2 Access Switch를 통해 라우터를 거쳐 인터넷에 도달할 것입니다. 그러면 반대측에서 라우터를 거쳐서 L2 스위치를 거쳐 전달받은 어떠한 서버가 있다고 가정했을 때, 그러면 이때 이 서버에서 특정 파일을 다운로드받는다고 했을 때 서버 측 입장에서는 이 파일이라는 정보를 송신하는 것이고 반대로 PC는 이 파일을 수신하는 것입니다.**

### 파일 크기와 패킷 분할의 현실

**그러면 이때 인터넷 구간에서 특정 데이터는 패킷의 형태로 전송될 것인데 이때 파일의 크기가 대략 1.4MB의 크기를 가진다고 했을 때 이 전송 단위인 패킷은 최대 1.4KB밖에 되지 않습니다. 파일과 패킷의 크기가 대략 1024배 정도나 차이가 나게 됩니다. 해당 파일은 보내는데 있어서 대략 1000개 이상의 패킷으로 변경해서 전송해야 됩니다.**

```
크기 비교 및 분할 계산:

원본 파일: 1.4MB = 1,440,000 bytes
패킷 최대: 1.4KB = 1,400 bytes (실제 payload)

분할 계산:
1,440,000 ÷ 1,400 ≈ 1,029개 패킷

실제 분할 과정:
┌─────────────────────────────────────────┐
│ 1.4MB 파일                              │
│ ┌─────┬─────┬─────┬─────┬─────┬─────┐   │
│ │1.4KB│1.4KB│1.4KB│ ... │1.4KB│잔여 │   │
│ └─────┴─────┴─────┴─────┴─────┴─────┘   │
│ ↓     ↓     ↓     ↓     ↓     ↓       │
│ P1   P2   P3   ...  P1028 P1029      │
└─────────────────────────────────────────┘

각 패킷의 구조:
[IP Header][TCP Header][1400 bytes Data]
    20B        20B         1400B = 1440B (MTU 내)
```

### TCP 연결 지향 통신

**결국 PC랑 서버라고 말했지만 정확하게 말하자면 어떠한 프로세스가 파일을 보내거나 받는 것입니다. 그래서 이 파일을 TCP/IP로 보낸다고 했을 때 이 TCP는 연결 지향형(connection oriented) protocol인데 그 연결이라는 걸 진행합니다.**

### 전화 통화와의 비교

**뭐 연결이라는 것이 복잡할 것이 없이 우리가 전화를 상대방에게 걸 때 전화 신호 대기음이 울렸다가 전화를 받으면 "여보세요" 하면서 그때부터 통화가 시작되는 것처럼 이 연결이 통화 연결되는 것이랑 같습니다.**

전화 통화 vs TCP 연결:

전화 통화:
발신자: "뚜뚜뚜..." (다이얼)
수신자: "여보세요?" (응답)
발신자: "안녕하세요" (확인)
→ 통화 시작

TCP 3-Way Handshake:
Client: SYN (연결 요청)
Server: SYN-ACK (요청 수락 + 확인 요청)  
Client: ACK (확인 응답)
→ 연결 설립 완료

공통점:
- 양방향 확인 과정
- 연결 설립 후 데이터 교환
- 연결 종료 절차 필요

### 서버 측 송신 과정

### 시스템 구조와 버퍼링

```
서버 측 송신 구조:

                              Server
                                 │
                            Process ──────→ │ 프로세스 버퍼      │
                                 │         │                  │
                                 ↓         └──────────────────┘
User Mode              소켓 인터페이스 (TCP/IP 추상화)
                                 │         ┌──────────────────┐
                                 ↓  I/O    │ 소켓 버퍼        │
─────────────────────────────────────────────────────────────
Kernel Mode                    TCP         └──────────────────┘
                                 │
                                 ↓  
                                IP
                                 │
                                 ↓
S/W                           Driver
                                 │
─────────────────────────────────────────────────────────────
H/W                           NIC           HDD,SSD ← File 1.4MB 
                                 │
                          물리적 신호로 변환
```

### 버퍼의 역할과 I/O 방식

**소켓의 본질은 파일이고 여기에 대해서 입출력이 발생합니다. 그런데 이런 입출력이 일어날 때는 이 file 혹은 소켓에 추가적으로 어떠한 것이 있기 마련인데 그게 바로 메모리 공간 버퍼가 있기 마련입니다. 그래서 이 버퍼가 있으면 Buffered I/O를 하는 것이고 없이 직접 입출력을 하면 non-buffered I/O를 하게 됩니다.**

```
버퍼 종류와 I/O 방식:

Buffered I/O:
Application → Process Buffer → Socket Buffer → Network
- 장점: 효율적 메모리 사용, 성능 최적화
- 단점: 복사 오버헤드, 지연 가능성

Non-Buffered I/O (Direct I/O):  
Application → Network (직접)
- 장점: 낮은 지연시간, 단순함
- 단점: 시스템 콜 오버헤드, 성능 저하

실제 시스템에서는 Buffered I/O가 일반적:
┌─────────────────────────────────────────┐
│ 1. 파일 → 프로세스 버퍼 (read/fread)     │
│ 2. 프로세스 버퍼 → 소켓 버퍼 (send)     │
│ 3. 소켓 버퍼 → TCP 처리 → 네트워크      │
└─────────────────────────────────────────┘
```

### 파일 분할과 스트림 처리

### 버퍼 크기와 분할 전략

**이 소켓뿐만 아니라 프로세스에서도 개발자가 이 파일을 읽어와야 합니다. 당연히 이때도 역시 버퍼가 존재할 것입니다. 이 버퍼의 크기는 개발자가 정하기 나름입니다.**

**그러면 지금 우리가 처리해야 되는 파일의 크기는 1.4MB입니다. 그러면 이 버퍼의 크기 역시 1.4MB일까요? 그렇지는 않습니다. 이 크기는 앞서 개발자가 정합니다.**

```
버퍼 크기 전략:

파일 크기: 1.4MB (1,440,000 bytes)

가능한 버퍼 크기 옵션:
┌─────────────────────────────────────────┐
│ 소형 버퍼: 4KB (4,096 bytes)            │
│ • 메모리 효율적                         │
│ • 많은 시스템 콜 필요 (360회)           │
│ • 오버헤드 증가                         │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│ 중형 버퍼: 64KB (65,536 bytes)          │
│ • 균형 잡힌 성능                        │
│ • 적절한 시스템 콜 횟수 (22회)          │
│ • 일반적인 선택                         │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│ 대형 버퍼: 1.4MB (전체 파일)            │
│ • 단일 시스템 콜                        │
│ • 메모리 사용량 증가                    │
│ • 지연 시간 증가 가능                   │
└─────────────────────────────────────────┘
```

개발자 코드 예시:

```c
char buffer[65536];  // 64KB 버퍼
while ((bytes_read = read(fd, buffer, sizeof(buffer))) > 0) {
    send(socket, buffer, bytes_read, 0);
}

```

### 퍼즐 조각 비유와 스트림 처리

그래서 우리는 이 파일을 마치 완성된 퍼즐조각이라 생각하고 이 퍼즐조각 중 일부분을 잘라서 프로세스가 관리하는 버퍼에 보내게 됩니다. 메모리에 원본 파일이라고 말할 수 있는 데이터 일부분을 가져와서 복사해서 버퍼에 넣습니다.

파일 분할과 스트림 처리:
원본 파일 (1.4MB 퍼즐):

```
┌─────────────────────────────────────────┐
│ ┌───┬───┬───┬───┬───┬───┬───┬───┬───┐   │
│ │ 1 │ 2 │ 3 │ 4 │ 5 │ 6 │ 7 │ 8 │...│   │
│ └───┴───┴───┴───┴───┴───┴───┴───┴───┘   │
│ 64KB 단위로 읽기                        │
└─────────────────────────────────────────┘
```

스트림 처리 순서:
1차: read() → 프로세스 버퍼에 조각 1 복사
send() → 소켓 버퍼에 조각 1 복사 → 전송

2차: read() → 프로세스 버퍼에 조각 2 복사

send() → 소켓 버퍼에 조각 2 복사 → 전송

...계속 반복...

스트림 특성:

- 연속적 데이터 흐름
- 순차적 처리
- 파일 끝까지 계속
- 물 흐르듯 자연스러운 전송

### TCP Segmentation과 캡슐화

### 세그먼트 분할과 순서 관리

**그 다음에 프로세스에서 사용하는 버퍼에서 다시 소켓 버퍼로 복사가 발생합니다. 네트워크에서 입출력을 send/Receive 하는 것이니 프로세스가 파일의 데이터 일부분을 send 할 때 소켓 버퍼에 복사가 발생합니다.**

**이런 식으로 하나의 block 가져와서 전송이 일어나는데 user mode에서 kernel mode 넘어갈 때 TCP를 만나고 이 지점에서 분해가 일어납니다. 전달된 소켓 버퍼의 데이터를 세그먼트 단위로 분해하는 segmentation이 일어납니다.**

TCP Segmentation 과정:
소켓 버퍼 (64KB):

```
┌─────────────────────────────────────────┐
│ 65,536 bytes 스트림 데이터               │
└─────────────────────────────────────────┘
↓ TCP Segmentation
┌─────────────────────────────────────────┐
│ Segment 1: [TCP Header][1460 bytes] SEQ=0    │
│ Segment 2: [TCP Header][1460 bytes] SEQ=1460 │
│ Segment 3: [TCP Header][1460 bytes] SEQ=2920 │
│ ...                                     │
│ Segment 45:[TCP Header][196 bytes]  SEQ=64340│
└─────────────────────────────────────────┘
```

TCP 헤더의 순서 번호 (Sequence Number):

- SEQ 0: 첫 번째 바이트 위치
- SEQ 1460: 1461번째 바이트부터 시작
- SEQ 2920: 2921번째 바이트부터 시작
  → 수신 측에서 순서 재조립에 사용

### 패킷 전송과 Frame 변화

### 택배 트럭 비유

그래서 소켓 스트림을 segmentation 해서 segment 단위로 데이터를 잘라왔을 때 이 데이터의 순서를 기록합니다. 이렇게 이 세그먼트가 한층 더 내려가서 IP를 만나서 이 세그먼트를 패킷 안에 넣고 잘 포장하고 송장을 붙입니다.

이렇게 패킷이 만들어지고 L2 계층으로 내려가고 해서 밖으로 나가게 됩니다. 앞서 택배 기사님한테 전달해야 되는데 택배 기사님이 택배 전달을 위해 어떤 트럭 한 대를 가지고 옵니다. 이 트럭 속에 우리의 패킷을 실어 가게 되는데 이때 이 트럭이 Frame입니다.

### Frame의 동적 변화

이때 이 Frame이 목적지까지 바로 일직선으로 쭉 갈까요? 우리가 배송을 할 때 기사님이 트럭을 타고 목적지까지 바로 가지는 않습니다. 트럭으로 갔다가 내렸다가 다시 다른 트럭으로 옮겨 담아서 최종적으로 목적지까지 가게 됩니다.

그래서 이 packet은 유지가 되지만 그 밖에 있는 프레임은 수시로 변경됩니다. 즉 유통 과정에서 트럭을 갈아탑니다.

패킷 전송과 Frame 변화:

```
[Ethernet Header A][IP Packet][FCS A]
↓ L2 스위치에서 처리
라우터 A에 도착:
```

- Ethernet Header A 제거
- IP Packet 추출
- 라우팅 테이블 확인
- 새로운 인터페이스로 전송

```
라우터 A → 라우터 B:
[PPP Header][IP Packet][PPP Trailer]
↓ 인터넷 백본
라우터 B → 라우터 C:
[MPLS Header][IP Packet][MPLS Trailer]
↓ 목적지 ISP
목적지 LAN:
[Ethernet Header B][IP Packet][FCS B]
```

핵심 원리:

- IP Packet은 전 구간 동일 유지
- Frame은 각 네트워크 구간별로 변경
- 택배(패킷) 내용은 같지만 트럭(Frame)은 계속 교체

### 수신 측 처리 과정

### Decapsulation과 버퍼 처리

```
수신 측 처리 구조:

                              PC
                                 │
                            Process ←───── │ 프로세스 버퍼      │
                                 │        │                  │
                                 ↑        └──────────────────┘
User Mode              소켓 인터페이스 (TCP/IP 추상화)
                                 │        ┌──────────────────┐
                                 ↑  I/O   │ 소켓 버퍼        │
─────────────────────────────────────────────────────────────
Kernel Mode                    TCP        └──────────────────┘
                                 │
                                 ↑  
                                IP
                                 │
                                 ↑
S/W                           Driver
                                 │
─────────────────────────────────────────────────────────────
H/W                           NIC
                                 │
                          물리적 신호로 수신
```

**트럭이 목적지까지 오게 되면 당연하게도 위에서 했던 일을 정반대로 하지 않을까요? 이 Frame이 도착한 다음에(당연히 처음 전달했던 트럭과는 다른 트럭이다) 안에 있는 택배 패킷을 꺼냅니다.**

### 계층별 Decapsulation

**이번에는 반대로 올라갑니다. L2 수준에서 트럭에서 하차가 일어납니다. 그다음에 IP 쪽으로 올려서 택배 박스를 버리고 안에 있는 내용물을 다시 TCP로 올립니다. 즉, 프레임에서 패킷을 꺼내고 꺼낸 패킷을 열어서 세그먼트를 꺼냅니다.**

```
Decapsulation 단계별 처리:

1. L1→L2: 물리 신호 → Frame 복원
   [Eth Header][IP Packet][FCS]

2. L2→L3: Frame Header 제거  
   [IP Header][TCP Segment]

3. L3→L4: IP Header 제거
   [TCP Header][Data]

4. L4→App: TCP 처리 후 소켓 버퍼에 저장
   Data → Socket Buffer

5. App: 소켓 버퍼 → 프로세스 버퍼
   recv() 시스템 콜로 데이터 읽기

역순 처리의 핵심:
- 각 계층에서 자신의 헤더만 제거
- 상위 계층으로 payload 전달  
- 최종적으로 원본 데이터 복원
```

### TCP 확인 응답(ACK) 메커니즘

### 택배 확인과 ACK

**이렇게 어떤 데이터 하나를 보낼 때 층마다 무언가가 층층이 쌓이는데 전체적으로 송신하는 과정에서는 항상 Encapsulation이 발생하고 반대로 수신하는 쪽에서는 Decapsulation이 발생합니다.**

**송신하는 측과 동일하게 소켓 버퍼에 전달받은 세그먼트 조각이 버퍼로 올라갑니다. 지금처럼 I/O 버퍼에다가 세그먼트를 쌓아주는 역할을 운영체제의 TCP 스택에서 처리해줍니다.**

### ACK 응답과 흐름 제어

**이때 수신 측에서 TCP에서 전달받은 패킷을 버퍼에 채운 다음에 이 TCP는 연결 지향이기 때문에 운영체제에서 "내가 지금 너가 전달한 택배를 잘 받았어" 하고 피드백을 줍니다. 그 피드백을 ACK(acknowledgement)라고 합니다.**

```
ACK 메커니즘:

송신 측 동작:
Packet 1 (SEQ 0~1459) 전송
Packet 2 (SEQ 1460~2919) 전송
        ↓ 전송 후 대기
ACK 2920 수신 ← "1,2번 패킷 잘 받았음"
        ↓ 확인 후 계속 전송
Packet 3 (SEQ 2920~4379) 전송

수신 측 동작:  
Packet 1 수신 → 버퍼 저장
Packet 2 수신 → 버퍼 저장
        ↓ 연속 수신 확인
ACK 2920 전송 → "다음은 2920번부터 보내"

ACK 번호의 의미:
ACK 2920 = "2920번 바이트부터 기다리고 있음"
         = "0~2919번까지는 잘 받았음"
```

**지금 패킷을 2번까지 받았고 3이라고 ACK라고 보냅니다. 이 말은 1,2번까지는 잘 받았다는 뜻입니다.**

**그래서 보낸 측에서 1번과 2번 패킷을 보내고 일정 수준 대기를 합니다. 그 이유는 내가 지금 택배를 보냈는데 잘 받았나? 하고 응답이 올 때까지 기다립니다. acknowledgement 3이 올 때까지 기다립니다. 3을 응답받으면 그때 정말로 3번의 패킷을 전달합니다.**

### TCP 장애 상황과 대처

### 4가지 주요 TCP 문제

**근데 이때 1,2번을 보내면 그 보낸 데이터를 프로세스 측에서 비워줘야 합니다. 그래서 이 ACK 3을 보낼 때 현재 여유 공간에 대한 정보 역시 같이 전달합니다.**

**여유 공간을 왜 언급했냐 하면 이 네트워크에서 데이터가 항상 잘 가면 좋은데 생각보다 불안정합니다. 그래서 해당 구간에서 장애가 발생하는 경우가 많은데 가장 대표적인 TCP 관련한 장애들이 있습니다.**

### 1. Lost Segment (세그먼트 손실)

**수신 측에서 택배를 잃어버린 것이 아니라 택배가 전달되는 과정에서 유실된 것입니다. 이 데이터의 전송 과정은 아주 정교한 타이머로 동작합니다. 그래서 어떤 데이터를 보내고 잘 받았으면 ACK와 같은 응답이 와야 합니다.**

**송신 측에서 잘 받고 있겠지 하고 일정 수준의 데이터를 쭉 보낸 다음에 응답이 없으면 송신 측에서 다시 똑같은 데이터를 보낼 때가 있습니다.**

```
Lost Segment 처리:

정상 상황:
송신: Packet 1, 2, 3 전송
수신: ACK 4 응답 (1,2,3 모두 수신)

손실 상황:
송신: Packet 1, 2, 3 전송
     Packet 2 손실! ❌
수신: Packet 1 ✓, Packet 3 ✓ 수신
     ACK 2 전송 (2번 없어서 1번까지만 확인)
     
송신: 타임아웃 후 Packet 2 재전송
수신: Packet 2 수신 → ACK 4 전송

Timeout 메커니즘:
- RTO (Retransmission Timeout) 계산
- RTT (Round Trip Time) 기반 동적 조정
- 지수적 백오프로 재전송 간격 증가
```

### 2. Re-Transmission (재전송)

**즉 내가 ACK를 보낸 시점과 동시에 상대방도 동일한 데이터를 보내는 경우가 있습니다. 또 수신 측에 다시 ACK 3을 보냅니다. 즉 이 ACK가 중복돼서 여러 번 나갑니다.**

```
Re-transmission 시나리오:

타이밍 문제:
T1: 송신측 Packet 2 전송
T2: 수신측 ACK 3 전송 (응답)
T3: 송신측 타임아웃 → Packet 2 재전송
T4: 송신측 ACK 3 수신 (늦게 도착)
T5: 수신측 중복 Packet 2 수신 → ACK 3 재전송

결과:
- 송신측: 불필요한 재전송 발생
- 수신측: 중복 ACK 전송
- 네트워크: 대역폭 낭비

대처 방법:
- Fast Retransmit: 3개 중복 ACK 시 즉시 재전송
- SACK (Selective ACK): 부분 수신 정보 제공
- 타임스탬프 옵션으로 RTT 정확성 향상
```

### 3. Out of Order (순서 뒤바뀜)

**그리고 가끔 out of order라고 해서 1번하고 2번을 받고 3번이 와야 하는데 갑자기 4번이 도착한 경우 혹은 4번이 먼저 오고 3번이 온 경우 이런 형태를 out of order라고 합니다. 그래서 이러한 경우는 TCP 스택 운영체제에서 어느 정도 보정을 해줍니다.**

```
Out of Order 처리:

정상 순서: 1 → 2 → 3 → 4
실제 도착: 1 → 2 → 4 → 3

TCP 재조립 버퍼:
┌─────────────────────────────────────────┐
│ SEQ 0~1459: ✓ (Packet 1)               │
│ SEQ 1460~2919: ✓ (Packet 2)            │
│ SEQ 2920~4379: ❌ (Packet 3 Missing)    │
│ SEQ 4380~5839: ✓ (Packet 4) - 대기중   │
└─────────────────────────────────────────┘

처리 과정:
1. Packet 1,2 수신 → ACK 2920 전송
2. Packet 4 수신 → 여전히 ACK 2920 전송 (3번 대기)
3. Packet 3 수신 → 모든 패킷 연결 → ACK 5840 전송

TCP 스택의 자동 보정:
- 순서 재조립 (Reordering)
- 버퍼링으로 누락 패킷 대기
- 연속된 데이터만 애플리케이션에 전달
- Duplicate ACK로 송신측에 힌트 제공
```

### 4. Zero Window (윈도우 크기 0)

**그리고 4번은 Zero Window라고 해서 여유 공간이 없는 경우입니다. 위에처럼 소켓 버퍼의 여유 공간을 window size라고 합니다. 그러면 여유 공간이 왜 없냐 하면 네트워크상에서 통신이 정상적으로 잘 이루어졌는데 프로세스가 이 버퍼를 어떠한 문제로 인해 비워주지 않아서 발생합니다.**

**즉 네트워크의 송수신 속도가 프로세스가 이 버퍼를 처리하는 속도보다 빠르다는 것입니다.**

```
Zero Window 상황:

소켓 버퍼 상태:
┌─────────────────────────────────────────┐
│ ████████████████████████████████████████ │ 
│ 100% 가득참 (여유 공간 0)                │
└─────────────────────────────────────────┘

속도 불일치:
네트워크 수신 속도: 100 Mbps
프로세스 처리 속도: 10 Mbps
→ 버퍼가 쌓이는 속도 > 비워지는 속도

TCP Window 메커니즘:
송신측: "더 보낼까?"
수신측: "윈도우 크기 = 0 (못 받아!)"
송신측: 전송 중단, 주기적으로 윈도우 크기 확인
수신측: 버퍼 여유 생기면 윈도우 크기 업데이트

실제 상황 예시:
- 웹서버가 대용량 파일 전송
- 클라이언트 애플리케이션이 파일 쓰기 지연 (디스크 I/O 병목)
- 소켓 버퍼 가득참 → Zero Window 발생
```

### 문제 원인 분석

**1번은 네트워크 문제, 2번 네트워크나 엔드포인트의 문제, 3번은 네트워크 문제, 4번은 엔드포인트 Application의 문제일 가능성이 높습니다.**

```
TCP 문제 분류 및 대처:

┌─────────────────────────────────────────┐
│ 네트워크 인프라 문제                    │
├─────────────────────────────────────────┤
│ 1. Lost Segment                         │
│ • 원인: 라우터 혼잡, 패킷 드롭          │
│ • 대처: QoS 설정, 대역폭 확장           │
│                                         │
│ 3. Out of Order                         │
│ • 원인: 다중 경로, 라우팅 변경          │
│ • 대처: 경로 고정, 로드밸런싱 개선      │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│ 혼합 문제 (네트워크 + 엔드포인트)       │
├─────────────────────────────────────────┤
│ 2. Re-transmission                      │
│ • 원인: 타임아웃 설정, RTT 변동         │
│ • 대처: TCP 튜닝, 타임아웃 조정         │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│ 애플리케이션 문제                       │
├─────────────────────────────────────────┤
│ 4. Zero Window                          │
│ • 원인: 애플리케이션 처리 속도 저하     │
│ • 대처: 코드 최적화, 버퍼 크기 조정     │
└─────────────────────────────────────────┘
```

이렇게 **TCP/IP 송수신의 전체 과정을 에펠탑 택배 비유와 실제 기술적 세부사항을 결합**하여 이해하면, **네트워크 통신이 단순한 데이터 전송이 아니라 매우 정교한 시스템들의 협력**이라는 것을 깊이 있게 파악할 수 있습니다. **특히 TCP의 4가지 주요 문제들과 그 원인을 이해**하는 것은 **실무에서 네트워크 성능 문제를 해결**하는 데 핵심적인 지식이 됩니다!